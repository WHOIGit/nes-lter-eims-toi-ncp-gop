---
title: "NES-LTER EIMS TOI and NCP-GOP Transects"
author: "Jaxine Wolfe, Kate Morkeski, Stace Beaulieu"
date: "August 12, 2022"
output: html_document
---

## R Markdown Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# set environment timezone to UTC
Sys.setenv(TZ = "UTC")

# set path to root of project
library(here)
here("nes-lter-eims-toi-ncp-gop")

# source from Github
remotes::install_github("WHOIGit/ediutilities")
library(ediutilities)

# define source for functions developed for the EDI packaging workflow
#source("edi-utilities.R")
# specific to this workflow
source("prep-eims-toi-data.R")

# define R packages to require
libs <- c("glue", "tidyverse", "readxl", "lubridate", "devtools", "EMLassemblyline", "EML", "maps", "xml2")
# load libraries
lapply(libs, require, character.only = TRUE)

```

## EIMS-TOI-TRANSECT DATA ------------

## Read in List of Cruises to Include in Package, with Cruise-Specific Info

```{r}

cruise_list <- read_csv("cruise_list.csv", col_names = TRUE)
# include in cruise_list only cruises to assemble in cruise_list (or find a good way to skip rows in loop below)

#years <- unique(cruise_list$year)

# identify cruises in each year
# for (val in years){
#     #cruiseyear <- cruise_list$year[i]
#   this_year <- cruise_list %>% filter(year == val) 
#   these_cruises <- this_year$cruise_id
#   assign(paste0(val, "_cruises"), these_cruises)
#   }

```

## Read in Provided CSV Files

Add a toi_source field to the TOI data set to clarify whether a bottle was sampled from Niskin vs. underway water. 
Assign underway sampling depth.

## Supply correct UTC datetime, depth, and lat long for bottle samples

Issues: 
  • The datetime_utc for bottle-sampled data represents the cast start time, NOT the time at which the bottle was fired
  • Differences in the given depth vs. those in the bottle summary

Solution: 
  • load in the bottle summary for the appropriate cruise
  • find the associated cast based on nearest time
  • find the time at which the bottle was fired based on API cast and PI-provided niskin
  • find the depth, latitude, and longitude for that bottle based on nearest time
  • compare the given depth to api provided
  
  Using the corrected datetimes, pull geospatial data from the underway log

```{r}

# TOI data

# for each item in cruiselist, filter cruise_list by cruise_id, read in toi_input, assign column names, populate cruise id, convert datetime format, ensure rows are in order, return dataframe idenfied with cruise id
# uses functions in prep-eims-toi-data.R

# include in cruise_list only cruises to assemble. 
# this makes no modifications to the Niskins of 99, Depth 999. They are filtered out in next chunk. 
  
 #  for each cruise in cruise_list, read in toi data and edit columns as needed 
for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  # function assigns column names and adds cruise identifier column
  toi <- read_toi(this$toi_input, this$cruise_id)
  # function formats datetime and puts rows in order
  toi <- time_toi(toi$datetime_utc_matlab)
  
  # function identifies toi source based on Niskin value and assigns underway sample depth to ship's intake depth (from 0 m)
  # in future check for nonzero depths before assigning
  toi <- set_toi_source(toi$niskin, toi$depth_matlab, toi$toi_source)
  
  # read in api data for Niskin samples for given cruise
  summary <- read_from_api(type = "summary", cruises = cruisename)
  
  # create columns to populate from API 
  toi$cast <- NA_integer_
  toi$depth_API <- NA_integer_
  toi$datetime_utc_API <- as.POSIXct(NA)
  toi$latitude_API <- NA_integer_
  toi$longitude_API <- NA_integer_
  
  # match API data to TOI data based on datetime
  # get cast, depth, dateime, lat, long from API
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if underway
    if (is.na(nisk)) {
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - summary$date))
    smry_cast <- summary$cast[ind]
    
    # populate cast column from summary
    toi$cast[i] <- smry_cast
    
    # store cast to find bottle time
    smry <- summary %>% filter(cast == smry_cast &
                                 niskin == nisk)
    
    # case: smry subset is empty  
    if (nrow(smry) == 0) {
      print(paste0(cruisename, " Niskin ", nisk, " not found in bottle summary for cast ", smry_cast))
      next
    }
    
    # add parameters from API to TOI data frame
    toi$datetime_utc_API[i] <- smry$date
    toi$depth_API[i] <- smry$depth
    toi$latitude_API[i] <- smry$latitude
    toi$longitude_API[i] <- smry$longitude
  }
  
  # make new datetime and depth columns that combine PI-provided column (for underway) with API-provided column (for niskin)
  toi <- toi %>%
    mutate(datetime_utc = case_when(toi_source =="toi_underway" ~ datetime_utc_matlab,
                                    toi_source == "toi_niskin" ~ datetime_utc_API)) %>%
    mutate(depth = case_when(toi_source =="toi_underway" ~ depth,
                             toi_source == "toi_niskin" ~ depth_API)) %>%
    mutate(depth = round(depth, 3)) # round to 1 or 2 decimal places instead of to milimeter? 
  
  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for underway bottle samples, match API lat long to sample based on datetime
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if niskin
    if (!is.na(nisk)) {
      next
    }
    
    # skip row if time is missing
    if (is.na(sampletime)){
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    # different columns depending on vessel
    # toi$latitude_API[i] <- underway$latitude[ind]   
    # toi$longitude_API[i] <- underway$longitude[ind]
    if(str_detect(cruisename, 'EN') ){
    toi$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    toi$longitude_API[i] <- underway$gps_furuno_longitude[ind]
    }
    if(str_detect(cruisename, 'AR') ){
    toi$latitude_API[i] <- underway$dec_lat[ind]
    toi$longitude_API[i] <- underway$dec_lon[ind]
    }
  }

  
  #output data frame for cruise
  assign(paste0("toi_", cruisename), toi) 

}  
  
```

# Combine individual cruise toi data into one dataframe

```{r}

# combine all cruises
bottle <- rbind(toi_EN608, toi_EN617, toi_AR31A, toi_EN627, toi_EN644, toi_AR34B)

# remove samples recorded with Niskin 99 (and depth 999). These were related to an experiment. 
niskin99 <- bottle %>% filter(niskin == "99")
bottle <- bottle %>% filter(niskin != "99" | is.na(niskin))

# exclude for now cruise EN644 casts affected by provided incorrect cast start time
bottle$cast_time <- ifelse(bottle$cruise == "EN644" & bottle$cast == 8 | 
                               bottle$cruise == "EN644" & bottle$cast == 9 | 
                               bottle$cruise == "EN644" & bottle$cast == 18 | 
                               bottle$cruise == "EN644" & bottle$cast == 20 |
                               bottle$cruise == "EN644" & bottle$cast == 26 |
                              bottle$cruise == "AR34B" & bottle$cast == 18,
                          yes = "flag", 
                          no = NA)

bottlecasttime <- bottle %>% filter(!is.na(cast_time))

bottle <- bottle %>% filter(is.na(cast_time))
bottle <- bottle %>% select(-cast_time)

# ensure rows are in time order
bottle <- bottle[order(bottle$datetime_utc),]

```
## QA for TOI data

• compare the provided time to API-matched time
• compare the provided depth to API-matched depth
• check for Niskins not found in API
• check for samples recorded as Niskin with depth of 0
• check for underway samples with provided depth not 0
• isolate underway samples for visual comparison to event log

```{r}

# check time differences
# add time difference column
bottle$time_diff <- bottle$datetime_utc_matlab - bottle$datetime_utc_API
bottle$time_diff <- round(bottle$time_diff, 1)
# summarize time differences by cruise ## this is quick basic check of matching
toi_time_diffs <- bottle %>%
  group_by(cruise) %>%
  summarise(avg = mean(time_diff, na.rm = TRUE),
            min = min(time_diff, na.rm = TRUE),
            max = max(time_diff, na.rm = TRUE))


# isolate instances of large depth differences
bottle$depth_diff <- bottle$depth_matlab - bottle$depth_API
toi_depth_conflicts <- bottle %>% filter(depth_diff > 5 | depth_diff < -5)
toi_depth_conflicts$reason <- "large depth difference"

# isolate the niskins not found in API. This should be the same as samples printed in loop above except if removed in rbind chunk
toi_api_no_niskin <- bottle %>% filter(toi_source == "toi_niskin" & is.na(depth_API))
toi_api_no_niskin$reason <- "Niskin not found in API"

# check for samples recorded as Niskin with depth of 0
toi_niskin_0 <- bottle %>% filter(toi_source == "toi_niskin" & depth_matlab == 0)
toi_niskin_0$reason <- "Niskin with provided depth = 0"

# check for any underway samples with provided depth not 0 m 
toi_underway_depth <- bottle %>% filter(toi_source == "toi_underway" & depth_matlab != 0)
toi_underway_depth$reason <- "non-zero depth provided for underway sample"

toi_bottle_check <- rbind(toi_depth_conflicts, 
                          toi_api_no_niskin, 
                          toi_niskin_0, 
                          toi_underway_depth)
write.csv(toi_bottle_check, "toi_bottle_check.csv")

# isolate underway samples
# -> perform visual inspection of underway TOI bottle samples against event log
toi_uw_check <- bottle %>%
  filter(toi_source == "toi_underway") %>%
  select(-niskin, -cast, -depth_API, -datetime_utc_API, -depth_diff)

# putting this here for now so these samples are included in toi_bottle_check but excluded downstream
# exclude samples affected by incorrect datetime
bottle$cast_time <- ifelse(bottle$cruise == "AR31A" & is.na(bottle$datetime_utc_matlab)| # date is provided in input but time is not
                           bottle$cruise == "AR34B" & bottle$cast == 18|   # datetime provided doesn't match TOI cast log
                           bottle$cruise == "EN617" & bottle$cast == 29,   # datetime provided doesn't match rosette log (no TOI on cast 29)
                          yes = "flag", 
                          no = NA)

bottlecasttime <- bottle %>% filter(!is.na(cast_time))
bottle <- bottle %>% filter(is.na(cast_time))
bottle <- bottle %>% select(-cast_time)

# check for any missing datetime
sum(is.na(bottle$datetime_utc))
# missing_bottle_time <- bottle %>% filter(is.na(datetime_utc))

# # extract year to facilitate splitting data set by year
# bottle$year <- format(bottle$datetime_utc, "%Y")
# #check for any missing year
# sum(is.na(bottle$year))


```

## QA: Map TOI Bottle Sampling Locations & Plot TOI Parameters

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# Map Check
# bottle dataset does not have coordinates from matlab
# plot bottle API lat long
map_locs(df = bottle, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")
map_locs(df = toi_AR31A, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")
map_locs(df = toi_AR34B, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")
map_locs(df = toi_EN608, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")

# Plot measured parameters in bottle TOI dataset
ggplot(bottle, aes(x= datetime_utc_matlab, y = O2_Ar_ratio))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = O2_Ar_delta))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = cap_Delta_17O))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = d17O))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = d18O))+ geom_point()

```

## Write TOI output files 

```{r}

# # separate data by year
# bottle_2018 <- bottle %>% filter(year == "2018")
# bottle_2019 <- bottle %>% filter(year == "2019")

# define headers for columns in desired order
bottle_headers <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_API", "longitude_API", "toi_source", "cast", "niskin", "depth", "depth_matlab",  "O2_Ar_delta", "O2_Ar_ratio", "cap_Delta_17O", "d17O", "d18O")

# reorder columns as necessary
bottle_edi <- bottle[, bottle_headers]
# bottle_2018 <- bottle[, bottle_headers]
# bottle_2019 <- bottle[, bottle_headers]

# write files for upload to EDI
write.csv(bottle_edi, here("eims-toi-transect", 'toi-transect.csv'), row.names = FALSE)
# write.csv(bottle_2018, here("eims-toi-transect", 'toi-transect-2018.csv'), row.names = FALSE)
# write.csv(bottle_2019, here("eims-toi-transect", 'toi-transect-2019.csv'), row.names = FALSE)

```
## Read in EIMS data

```{r}

## EIMS data
# read in PI-provided csv data
# provide column names
# provide cruise id
# provide depth of underway intake
# convert datetime format
# order by time
# produce dataframe for each year

for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  eims <- read_eims(this$eims_input, this$cruise_id)
  eims <- time_eims(eims$datetime_utc_matlab)
  
  # check for samples without timestamp
  missingdate <- eims %>% filter(is.na(eims$datetime_utc_matlab))
  eims <- eims %>% filter(!is.na(eims$datetime_utc_matlab))
  
  assign(paste0("missingdate_", cruisename), missingdate)
 
  # initialize eims lat long columns
  eims$latitude_API <- NA_integer_
  eims$longitude_API <- NA_integer_

  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for eims file
  for (i in 1:nrow(eims)) {
    # store values
    sampletime <- eims$datetime_utc_matlab[i]  
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    
    if(str_detect(cruisename, 'EN') ){
    eims$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    eims$longitude_API[i] <- underway$gps_furuno_longitude[ind]
    }
    if(str_detect(cruisename, 'AR') ){
    eims$latitude_API[i] <- underway$dec_lat[ind]
    eims$longitude_API[i] <- underway$dec_lon[ind]
    }
  }
  
  #output data frame for cruise
  assign(paste0("eims_", cruisename), eims)
  
}

```

# Assemble EIMS data from all cruises

```{r}

# put all rows without timestamp into one dataframe
missingdates <- rbind(missingdate_EN608, missingdate_EN617, missingdate_AR31A, missingdate_EN627, missingdate_EN644, missingdate_AR34B)
# these are are row 1114 in input file RaEn608withbiosat and row 9845 in input file RaEn627withbiosat 

# write csv file for inspection
write.csv(missingdates, "eims_missingdates.csv", row.names = FALSE) 

# combine loop output from all cruises into one dataframe, excluding those with missing timestamp
eims_all <- rbind(eims_EN608, eims_EN617, eims_AR31A, eims_EN627, eims_EN644, eims_AR34B)

```

# QA for EIMS data

```{r}

# plot values to check for outliers

#plot matlab latitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()
# overlay API latitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()+geom_point(aes(y = latitude_API), color="yellow")

#plot matlab longitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()
# overlay API longitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()+geom_point(aes(y = longitude_API), color="yellow")

# plot eims matlab lat long
map_locs(df = eims_all, xvar = "longitude_matlab", yvar = "latitude_matlab", region = "transect", color = "cruise")
# plot eims lat long from API 
map_locs(df = eims_all, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")


# plot values
ggplot(eims_all, aes(x= datetime_utc_matlab, y = biosat))+ geom_point()
ggplot(eims_all, aes(x= datetime_utc_matlab, y = O2_Ar_ratio))+ geom_point()

```



## QA: Check for location differences

```{r}

# isolate instances of large lat/long differences
eims_all$lat_diff <- eims_all$latitude_matlab - eims_all$latitude_API
eims_all$long_diff <- eims_all$longitude_matlab - eims_all$longitude_API

# isolating differences of 0.002 decimal degrees = approximately 200 m 
pos_check <- eims_all %>%
  filter(abs(lat_diff) > 0.002 | abs(long_diff) > 0.002)
# EN617: identified two instances where values differ, and API output appears to be in error for those two data points. Use PI-provided lat/long. 
# AR34B supplies 39 of these 53 records! Based on REST API, not R2R

```

## Column Header Organization

```{r}

# separate data by year
eims_all$year <- format(eims_all$datetime_utc_matlab, "%Y")
eims_2018 <- eims_all %>% filter(year == "2018")
eims_2019 <- eims_all %>% filter(year == "2019")

# define headers for columns in desired order
eims_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "depth", "biosat", "O2_Ar_ratio")

# reorder columns as necessary
eims_all <- eims_all[, eims_headers]
eims_2018 <- eims_2018[, eims_headers]
eims_2019 <- eims_2019[, eims_headers]

# write files for upload to EDI
#write.csv(eims_all, here("eims-toi-transect", 'eims-transect.csv'), row.names = FALSE)
write.csv(eims_2018, here("eims-toi-transect", 'eims-transect-2018.csv'), row.names = FALSE)
write.csv(eims_2019, here("eims-toi-transect", 'eims-transect-2019.csv'), row.names = FALSE)

```

## EML Assembly: EIMS-TOI-transect

Assemble EML metadata templates based on the provided Excel template

```{r}

# define input files
edi_filename <- "eims-toi-transect"
metadata <- glue('{edi_filename}/{edi_filename}-info') 
project_folder <- here('eims-toi-transect')
pkg_id <- "knb-lter-nes.6.2"

# TODO: handle paths for templates output
# Make EML Templates 
excel_to_template(metadata_path = metadata, 
                  edi_filename = edi_filename, 
                  rights = "CCBY",
                  other_info = TRUE)

sheet_to_tsv('eims-toi-transect/eims-toi-transect-info.xlsx', 'CategoricalVariables',
             glue::glue('eims-toi-transect/catvars_toi-transect.txt'))

sheet_to_tsv('eims-toi-transect/eims-transect.xlsx', 'ColumnHeaders',
             glue::glue('eims-toi-transect/attributes_eims-transect-2018.txt'))

sheet_to_tsv('eims-toi-transect/eims-transect.xlsx', 'ColumnHeaders',
             glue::glue('eims-toi-transect/attributes_eims-transect-2019.txt'))

sheet_to_tsv('eims-toi-transect/toi-transect.xlsx', 'ColumnHeaders',
             glue::glue('eims-toi-transect/attributes_toi-transect.txt'))

EMLassemblyline::template_core_metadata(path= project_folder, license='CCBY')

```
Compute spatiotemporal coverage and generate EML

```{r}

# read data product csvs in order to get temporal and geographic coverage
toi_edi <- read.csv(here('eims-toi-transect/toi-transect.csv'))
eims_1 <- read.csv(here('eims-toi-transect/eims-transect-2018.csv'))
eims_2 <- read.csv(here('eims-toi-transect/eims-transect-2019.csv'))

# identify columns to generate temporal coverage and geographic coverage
temp_coverage <- temporal_coverage(append(toi_edi$datetime_utc, 
                                   append(eims_1$datetime_utc_matlab, eims_2$datetime_utc_matlab)))
lat <- append(toi_edi$latitude_API, append(eims_1$latitude_matlab, eims_2$latitude_matlab))
long <- append(toi_edi$longitude_API, append(eims_1$longitude_matlab, eims_2$longitude_matlab))

# generate EML
make_eml(path=project_folder,
         data.path= here('eims-toi-transect'),
         dataset.title= 'Oxygen-argon dissolved gas ratios using Equilibrator Inlet Mass Spectrometry (EIMS) and triple oxygen isotopes (TOI) from NES-LTER Transect cruises, ongoing since 2018',
         data.table=c('toi-transect.csv',
                      'eims-transect-2018.csv',
                      'eims-transect-2019.csv'),
         data.table.description=c("Data product low-frequency triple oxygen isotopes and oxygen-argon ratio from rosette and underway bottles", 
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2018", 
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2019"),
         data.table.name = c('toi-transect.csv',
                      'eims-transect-2018.csv',
                      'eims-transect-2019.csv'),
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.name = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = temp_coverage,
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = geographic_coordinates(lat, long),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node
# TODO: fix to handle paths
# for edi_utilities
#project_insert(edi_pkg = pkg_id, 
#               xml.path = project_folder)

# for ediutilities
project_insert(edi_pkg = pkg_id, filename = 'parent_project.txt')

```

## NCP-GOP-TRANSECT ----------

## To produce per-cruise NCP GOP package, select cruise from cruise list by manually editing package ID 

```{r}

# read in cruise-specific information
cruise_list <- read_csv("cruise_list.csv", col_names = TRUE)

# manually edit package id to select package to assemble 
this_pkg <- cruise_list %>% filter(package_id == "knb-lter-nes.13.1")

#identify input file names
ncp_gop_csv <- paste0(this_pkg$folder, "/input_data_csv/", this_pkg$ncp_gop_input, ".csv")
ncp_hifreq_input <- paste0(this_pkg$folder, "/input_data_csv/", this_pkg$ncp_hifreq_input, ".csv")

```

## Read in Provided CSV Files

```{r}

## read in PI-provided csv data
ncp_gop_input <- read_csv(ncp_gop_csv, col_names = FALSE)
ncp_hifreq_input <- read_csv(ncp_hifreq_input, col_names = FALSE)

## ncp-gop
# provide column names
if (this_pkg$cruise_id == "EN608" | this_pkg$cruise_id == "EN617"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop")
    ncp_gop_input$depth <- NA
    ncp_gop_input$niskin <- NA
    ncp_gop_input$quality <- 0
  }
if (this_pkg$cruise_id == "EN627"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin")
    ncp_gop_input$quality <- 0
  }
if (this_pkg$cruise_id == "EN644"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin", "quality")
}

## ncp-hifreq
# provide column names
colnames(ncp_hifreq_input) <- c("datetime_utc_matlab", "O2_Ar_ratio", "temp", "sal", "latitude_matlab", "longitude_matlab", "cumulative_dist", "biosat", "ncp", "k")
ncp_hifreq <- ncp_hifreq_input %>% select(-temp, -sal, -cumulative_dist)
# add depth column to high freq EIMS data
ncp_hifreq$depth <- 5

##convert datetime format
ncp_gop_input$datetime_utc_matlab <- as.POSIXct(ncp_gop_input$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")
ncp_hifreq$datetime_utc_matlab <- as.POSIXct(ncp_hifreq$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")


```

# For low-frequency data, handle missing data and provide quality flags

```{r}

sum(is.na(ncp_gop_input$gop))

# convert provided quality flag to iode quality flag
ncp_gop_input$iode_quality_flag <- NA_integer_
ncp_gop_input <- ncp_gop_input %>%
   mutate(iode_quality_flag = case_when(quality == 1  ~ 4,
                                        quality == 0  ~ 1,))

# convert any NaN to NA
ncp_gop_input <- ncp_gop_input %>% 
  mutate(gop=replace(gop, gop=="NaN", NA)) %>%
  mutate(ncp=replace(ncp, ncp=="NaN", NA)) %>%
  mutate(ncp_per_gop=replace(ncp_per_gop, ncp_per_gop=="NaN", NA))

# update quality flag to "missing" for the rows that were NaN
ncp_gop_input <- ncp_gop_input %>% 
 mutate(iode_quality_flag = case_when(is.na(gop) & iode_quality_flag == 1 ~ 9,
                                        TRUE  ~ iode_quality_flag))

# check for missing data                                                                               
sum(is.na(ncp_gop_input$gop))

# replace data with NA if iode quality flag is 4
ncp_gop_input <- ncp_gop_input %>%
  mutate(gop=replace(gop, iode_quality_flag==4, NA)) %>%
  mutate(ncp=replace(ncp, iode_quality_flag==4, NA)) %>%
  mutate(ncp_per_gop=replace(ncp_per_gop, iode_quality_flag==4, NA))

# check for NAs
sum(is.na(ncp_gop_input$gop)) 


```
# Exclude EN644 low-frequency samples affected by incorrect cast start time

```{r}

# ensure rows are in time order
ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]

# exclude for now cruise EN644 samples affected by incorrect cast start time
ncp_gop_input$cast_flag <- NA_integer_
ncp_gop_input <- ncp_gop_input %>%
   mutate(cast_flag = case_when(datetime_utc_matlab == "2019-08-22 00:57:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-22 03:10:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-22 04:23:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-23 15:45:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-23 16:55:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-23 23:45:00"  ~ 1,
                                datetime_utc_matlab == "2019-08-24 23:16:00"  ~ 1,
                                        TRUE ~ 0,))
sum(ncp_gop_input$cast_flag)

ncpcasttime <- ncp_gop_input %>% filter(ncp_gop_input$cast_flag == 1)

ncp_gop_input <- ncp_gop_input %>% filter(ncp_gop_input$cast_flag == 0)
ncp_gop_input <- ncp_gop_input %>% select(-cast_flag)

```


# Bind low-frequency data with TOI data to identify TOI_source and supply API-provided timestamp, latitude, and longitude

```{r}

## read in toi data product table
toi_transect <- read_csv("eims-toi-transect/toi-transect.csv")

# expect toi_transect to have rows with bottles deeper than surface
# filter for rows depth less than Rachel's depthcutoff 6 m
# check for length discrepancy
toi_transect_surface <- filter(toi_transect, cruise == this_pkg$cruise_id & depth_matlab <= 6)
nrow(toi_transect_surface)
nrow(ncp_gop_input)

## column bind if same length
# make sure using different column names
toi_transect_surface$datetime_utc <- as.POSIXct(toi_transect_surface$datetime_utc, format="%d-%b-%Y %H:%M:%OS")
toi_transect_surface <- toi_transect_surface %>%
  rename(datetime_utc_matlab_toi = datetime_utc_matlab) %>%
  rename(depth_matlab_toi = depth_matlab)
ncp_gop_input <- ncp_gop_input %>%
  #rename(datetime_utc_matlab_ncp = datetime_utc_matlab) %>%
  rename(depth_matlab_ncp = depth) %>%
  rename(niskin_matlab_ncp = niskin)
# make sure datetime_utc_matlab and datetime_utc_matlab_toi sorted or use dplyr::arrange
ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]
toi_transect_surface <- toi_transect_surface[order(toi_transect_surface$datetime_utc_matlab_toi),]
# bind
ncp_gop_transect_wide <- cbind(ncp_gop_input, toi_transect_surface)

## check for correct matching in bind
# boolean check niskin and/or depth_matlab and manually inspect datetime_utc_matlab equals datetime_utc_matlab_toi 
# EN617 ncpgop_input does not have niskin or depth 
# check that matlab timestamps match for combined data sets
ncp_gop_transect_wide <- ncp_gop_transect_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_toi ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_toi ~ 1))
sum(ncp_gop_transect_wide$timecheck)  

#reorder columns and drop toi data
gopheaders <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "latitude_API", "longitude_API","toi_source", "gop", "ncp", "ncp_per_gop", "iode_quality_flag")
ncp_gop_edi <- ncp_gop_transect_wide[, gopheaders]
# EN617: keeping both sets of lat/long in output but could exclude API lat/long since matlab lat/long were checked and found to be correct in eims-toi package


```

# Plot NCP-GOP parameters

```{r}

ggplot(ncp_gop_edi, aes(x= datetime_utc, y = gop))+ geom_point()
ggplot(ncp_gop_edi, aes(x= datetime_utc, y = ncp))+ geom_point()
ggplot(ncp_gop_edi, aes(x= datetime_utc, y = ncp_per_gop))+ geom_point()

```

## Add API lat/long for high-frequency data

```{r} 

#read in eims data product table
eims_transect <- read_csv("eims-toi-transect/eims-transect.csv")
#or use data frame already in environment

eims_transect_cruise <- filter(eims_transect,cruise == this_pkg$cruise_id)
nrow(eims_transect_cruise)

ncp_hifreq <- ncp_hifreq %>% filter(!is.na(datetime_utc_matlab))
nrow(ncp_hifreq)
# column bind if same length

# make sure using different column names
eims_transect_cruise <- eims_transect_cruise %>%
  rename(datetime_utc_matlab_eims = datetime_utc_matlab) %>%
  rename(latitude_matlab_eims = latitude_matlab) %>%
  rename(longitude_matlab_eims = longitude_matlab) %>%
  rename(depth_eims = depth) %>%
  rename(biosat_eims = biosat) %>%
  rename(O2_Ar_ratio_eims = O2_Ar_ratio) 
# make sure datetime_utc_matlab and datetime_utc_matlab_eims sorted or use dplyr::arrange
ncp_hifreq <- ncp_hifreq[order(ncp_hifreq$datetime_utc_matlab),]
#ncp_hifreq_wide <- left_join(ncp_hifreq, eims_transect_cruise)
ncp_hifreq_wide <- cbind(ncp_hifreq, eims_transect_cruise)

## check for correct matching in bind
# boolean check niskin and/or depth_matlab and manually inspect datetime_utc_matlab equals datetime_utc_matlab_eims
# EN617 ncpgop_input does not have niskin or depth 
# check that matlab timestamps match for combined data sets
ncp_hifreq_wide <- ncp_hifreq_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_eims ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_eims ~ 1))
sum(ncp_hifreq_wide$timecheck)  

#target columns
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab","depth", "biosat", "O2_Ar_ratio", "ncp", "k")
ncp_hifreq_edi <- ncp_hifreq_wide[, ncp_hifreq_headers]

```
# Plot NCP-GOP parameters in high-frequency data set

```{r}

ggplot(ncp_hifreq_edi, aes(x= datetime_utc_matlab, y = biosat))+ geom_point()
ggplot(ncp_hifreq_edi, aes(x= datetime_utc_matlab, y = O2_Ar_ratio))+ geom_point()
ggplot(ncp_hifreq_edi, aes(x= datetime_utc_matlab, y = ncp))+ geom_point()
ggplot(ncp_hifreq_edi, aes(x= datetime_utc_matlab, y = k))+ geom_point()

```


## QA: Map Sampling Locations

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# ncp gop discrete rates with matlab coordinates
map_locs(df = ncp_gop_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = NULL)

# # ncp gop discrete rates with API coordinates
# map_locs(df = ncp_gop, xvar = "longitude_API", yvar = "latitude_API",
#          region = "transect", colorvar = NULL)

# ncp high frequency
map_locs(df = ncp_hifreq_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = NULL)


```

# Column Header Organization

```{r}

# define the desired order of columns
#ncp_gop_headers <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "toi_source", "gop", "ncp", "ncp_per_gop")
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "depth", "ncp", "k")

# reorder columns as necessary
#ncp_gop_edi <- ncp_gop[, ncp_gop_headers]
ncp_hifreq_edi <- ncp_hifreq_edi [, ncp_hifreq_headers]

# write files for upload to EDI
write.csv(ncp_gop_edi, paste0(here(this_pkg$folder, this_pkg$gop_product), ".csv"), row.names = FALSE) #gop-transect
write.csv(ncp_hifreq_edi, paste0(here(this_pkg$folder, this_pkg$hifreq_product), ".csv"), row.names = FALSE) #ncp-transect

```


# EML Assembly: NCP-GOP-transect (Per Cruise)

This chunk outputs the final xml file for EDI through the following steps:

Step 1: Populating EML Assembly Line templates with metadata
Step 2: Calculating the geospatial and temporal coverage 
Step 3: Making the XML file 
Step 4: Inserting a custom NES-LTER parent project node 

```{r}

# define input for EML assembly
metadata <- this_pkg$metadata_file  #ncp-gop-transect-info
project_folder <- this_pkg$folder  
ncp_gop_file <- this_pkg$gop_product
ncp_hifreq_file <- this_pkg$hifreq_product
edi_data <- c(ncp_gop_file, ncp_hifreq_file)
file_descriptions <- c("Data product discrete rates of NCP and GOP from bottle TOI measurements integrated over the mixed layer", "Data product high frequency NCP derived from EIMS sampling of underway seawater")
pkg_id <- this_pkg$package_id

# Make EML Templates 
# if (file.exists(paste0(here(this_pkg$folder),"/", metadata, ".xlsx"))) {
#     print("metadata already exists")
#   } else {
xlsx_to_template(metadata.path = here(project_folder, metadata),
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = "ncp-gop-transect", 
                 rights = "CCBY")
# Discrete Rates
xlsx_to_template(metadata.path = here(project_folder, ncp_gop_file), 
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = ncp_gop_file, 
                 rights = "CCBY")
# Ncplter 
xlsx_to_template(metadata.path = here(project_folder, ncp_hifreq_file), 
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = ncp_hifreq_file, 
                 rights = "CCBY")
#}

# Data Coverage
# combine the dates and lat/lon for both datasets
# isolate date and geospatial columns for input
date_col <- as.Date(c(ncp_hifreq_edi$datetime_utc_matlab, ncp_gop_edi$datetime_utc_matlab))
lat_col <- c(ncp_hifreq_edi$latitude_matlab, ncp_gop_edi$latitude_matlab)
lon_col <- c(ncp_hifreq_edi$longitude_matlab, ncp_gop_edi$longitude_matlab)
# run function to determine geospatial and temporal coverage
coverage <- data_coverage(dates = date_col, lat = lat_col, lon = lon_col)

# Make EML
make_eml(path = here(project_folder),
         dataset.title = this_pkg$dataset_title,
         data.table = c(paste0(ncp_gop_file, ".csv"), paste0(ncp_hifreq_file, ".csv")),
         data.table.name = paste0(edi_data, ".csv"),
         data.table.description = file_descriptions,
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = c(coverage$startdate, coverage$enddate),
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = c(coverage$North, coverage$East, coverage$South, coverage$West),
         maintenance.description = "completed",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node
project_insert(edi_pkg = pkg_id, 
               xml.path = paste0(here(this_pkg$folder),"/"))

```
 
