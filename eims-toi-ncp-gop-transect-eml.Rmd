---
title: "NES-LTER EIMS TOI and NCP-GOP Transects"
author: "Jaxine Wolfe, Kate Morkeski, Stace Beaulieu"
date: "July 27, 2021"
output: html_document
---

## R Markdown Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# set environment timezone to UTC
Sys.setenv(TZ = "UTC")

#set path to root of project
library(here)
here("nes-lter-eims-toi-ncp-gop")

# define source for functions developed for the EDI packaging workflow
source("edi-utilities.R")
source("prep-rachel-data.R")

# define R packages to require
libs <- c("tidyverse", "readxl", "lubridate", "devtools", "EMLassemblyline", "EML", "maps", "xml2")
# load libraries
lapply(libs, require, character.only = TRUE)

```

## EIMS-TOI-TRANSECT DATA ------------

## Read in List of Cruises to Include in Package, with Cruise-Specific Info

```{r}

cruise_list <- read_csv("cruise_list.csv", col_names = TRUE)
# include in cruise_list only cruises to assemble in cruise_list (or find a good way to skip rows in loop below)

```

## Read in Provided CSV Files

Add a toi_source field to the TOI data set to clarify whether a bottle was sampled from Niskin vs. underway water. 
Assign underway sampling to a depth of 5m.

## Supply correct UTC datetime, depth, and lat long for bottle samples

Issues: 
  • The datetime_utc for bottle-sampled data represents the cast start time, NOT the time at which the bottle was fired
  • Differences in the given depth vs. those in the bottle summary

Solution: 
  • load in the bottle summary for the appropriate cruise
  • find the associated cast based on nearest time
  • find the time at which the bottle was fired based on API cast and PI-provided niskin
  • find the depth, latitude, and longitude for that bottle based on nearest time
  • compare the given depth to api provided
  
  Using the corrected datetimes, pull geospatial data from the underway log

```{r}

# TOI data

#for each item in cruiselist, filter cruise_list by cruise_id, read in toi_input, assign column names, populate cruise id, convert datetime format, ensure rows are in order, return dataframe idenfied with cruise id

# include in cruise_list only cruises to assemble. if additional cruises are included without toi_input, loop works but produces error when reaches missing toi_input
## currently this makes no modifications to the Niskins of 99, Depth 999
  
 #  for each cruise in cruise_list, read in toi data and edit columns as needed 
for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  toi <- read_toi(this$toi_input, this$cruise_id)
  toi <- time_toi(toi$datetime_utc_matlab)
  
  # identify toi source based on Niskin value and assign underway samples to depth 5 m 
  toi <- set_toi_source(toi$niskin, toi$depth_matlab, toi$toi_source)
  
  
  # read in api data for Niskin samples for given cruise
  summary <- read_from_api(type = "summary", cruises = cruisename)
  
  # create columns to populate from API 
  toi$cast <- NA_integer_
  toi$depth_API <- NA_integer_
  toi$datetime_utc_API <- as.POSIXct(NA)
  toi$latitude_API <- NA_integer_
  toi$longitude_API <- NA_integer_
  
  # match API data to TOI data based on datetime
  # get cast, depth, dateime, lat, long from API
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if underway
    if (is.na(nisk)) {
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - summary$date))
    smry_cast <- summary$cast[ind]
    
    # populate cast column from summary
    toi$cast[i] <- smry_cast
    
    # store cast to find bottle time
    smry <- summary %>% filter(cast == smry_cast &
                                 niskin == nisk)
    
    # case: smry subset is empty  
    if (nrow(smry) == 0) {
      print(paste0(cruisename, " Niskin ", nisk, " not found in bottle summary for cast ", smry_cast))
      next
    }
    
    # add parameters from API to TOI data frame
    toi$datetime_utc_API[i] <- smry$date
    toi$depth_API[i] <- smry$depth
    toi$latitude_API[i] <- smry$latitude
    toi$longitude_API[i] <- smry$longitude
  }
  
  # make new datetime and depth columns that combine PI-provided column (for underway) with API-provided column (for niskin)
  toi <- toi %>%
    mutate(datetime_utc = case_when(toi_source =="toi_underway" ~ datetime_utc_matlab,
                                    toi_source == "toi_niskin" ~ datetime_utc_API)) %>%
    mutate(depth = case_when(toi_source =="toi_underway" ~ depth_matlab,
                             toi_source == "toi_niskin" ~ depth_API)) %>%
    mutate(depth = round(depth, 3)) # round to 1 or 2 decimal places instead of to milimeter? 
  
  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for underway bottle samples, match API lat long to sample based on datetime
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if niskin
    if (!is.na(nisk)) {
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    toi$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    toi$longitude_API[i] <- underway$gps_furuno_longitude[ind]
  }


  #output data frame for cruise
  assign(paste0("toi_", cruisename), toi) 

}  
  
```

# Combine individual cruise toi data into one dataframe

```{r}


bottle <- rbind(toi_EN608, toi_EN617, toi_EN627, toi_EN644)


```
## QA for TOI data

• compare the given time to api provided
• compare the given depth to api provided
• isolate underway samples for visual comparison to event log
• check for samples recorded as Niskin with depth of 0


```{r}

# check time differences
bottle$time_diff <- bottle$datetime_utc_matlab - bottle$datetime_utc_API
bottle$time_diff <- round(bottle$time_diff, 1)
toi_time_diffs <- bottle %>%
  group_by(cruise) %>%
  summarise(avg = mean(time_diff, na.rm = TRUE),
            min = min(time_diff, na.rm = TRUE),
            max = max(time_diff, na.rm = TRUE))

# # store niskin lat & long for check after populating underway lat & long
# niskin_check <- bottle %>%
#     filter(toi_source == "toi_niskin") %>%
#     select(-niskin, -cast, -depth_API, -datetime_utc_API, -datetime_utc)

# isolate instances of large depth differences
bottle$depth_diff <- bottle$depth_matlab - bottle$depth_API
toi_depth_conflicts <- bottle %>% filter(depth_diff > 5 | depth_diff < -5)

# write.csv(depth_conflicts, "bottle-depth-conflicts.csv")

# isolate underway samples
# -> perform visual inspection of underway TOI bottle samples against event log
toi_check <- bottle %>%
  filter(toi_source == "toi_underway") %>%
  select(-niskin, -cast, -depth_API, -datetime_utc_API, -depth_diff)

# # confirm that this is not overwriting niskin lat long
# niskin2_check <- bottle %>%
#     filter(toi_source == "toi_niskin") %>%
#     select(-niskin, -cast, -depth_API, -datetime_utc_API, -datetime_utc, -depth_diff)
# # visual check, or join to niskin_check and check for differences in lat/long columns

# check for samples recorded as Niskin with depth of 0
if (any(bottle$depth_matlab == 0)) {
  toi_conflicts <- bottle[which(bottle$depth_matlab == 0),]
  print(toi_conflicts)
}

```

## QA: Map Sampling Locations

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# Map Check

# bottle dataset does not have coordinates from matlab
# plot bottle API lat long
map_locs(df = bottle, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")

````
## Read in EIMS data

```{r}

## EIMS data
# read in PI-provided csv data
# provide column names
# provide cruise id
# provide depth of 5 m 
# convert datetime format
# put in order by time
# produce dataframe for each cruise

for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  eims <- read_eims(this$cruise_id)
  eims <- time_eims(eims$datetime_utc_matlab)
  
  # check for samples without timestamp
  missingdate <- eims %>% filter(is.na(eims$datetime_utc_matlab))
  eims <- eims %>% filter(!is.na(eims$datetime_utc_matlab))
  
  assign(paste0("missingdate_", cruisename), missingdate)
 
  # initialize eims lat long columns
  eims$latitude_API <- NA_integer_
  eims$longitude_API <- NA_integer_

  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for eims file
  for (i in 1:nrow(eims)) {
    # store values
    sampletime <- eims$datetime_utc_matlab[i]  
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    eims$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    eims$longitude_API[i] <- underway$gps_furuno_longitude[ind]
  }
  
  #output data frame for cruise
  assign(paste0("eims_", cruisename), eims)
  
}
  

missingdates <- rbind(missingdate_EN608, missingdate_EN617, missingdate_EN627, missingdate_EN644)
# then remove per-cruise missingdate dataframes?
eims_all <- rbind(eims_EN608, eims_EN617, eims_EN627, eims_EN644)

```

# Initial QA for input csv data. 

```{r}

# plot values to check for outliers

#plot matlab latitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()
# overlay API latitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()+geom_point(aes(y = latitude_API), color="yellow")

#plot matlab longitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()
# overlay API longitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()+geom_point(aes(y = longitude_API), color="yellow")

# plot eims matlab lat long
map_locs(df = eims_all, xvar = "longitude_matlab", yvar = "latitude_matlab", region = "transect", color = "cruise")
# plot eims lat long from API 
map_locs(df = eims_all, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")

```



## QA: Check location differences

```{r}

# isolate instances of large lat/long differences
eims_all$lat_diff <- eims_all$latitude_matlab - eims_all$latitude_API
eims_all$long_diff <- eims_all$longitude_matlab - eims_all$longitude_API

# isolating differences of 0.002 decimal degrees = approximately 200 m 
pos_check <- eims_all %>%
  filter(abs(lat_diff) > 0.002 | abs(long_diff) > 0.002)
# EN617: identified two instances where values differ, and API output appears to be in error for those two data points. Use PI-provided lat/long. 

```


## Column Header Organization

```{r}

# define headers for columns in desired order
bottle_headers <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_API", "longitude_API", "toi_source", "cast", "niskin", "depth", "depth_matlab",  "O2_Ar_delta", "O2_Ar_ratio", "cap_Delta_17O", "d17O", "d18O")
eims_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "depth", "biosat", "O2_Ar_ratio")

# reorder columns as necessary
bottle_edi <- bottle[, bottle_headers]
eims_edi <- eims_all[, eims_headers]

# write files for upload to EDI
write.csv(bottle_edi, here("eims-toi-transect", 'toi-transect.csv'), row.names = FALSE)
write.csv(eims_edi, here("eims-toi-transect", 'eims-transect.csv'), row.names = FALSE)

```

# EML Assembly: EIMS-TOI-transect

This chunk outputs the final xml file for EDI through the following steps:

Step 1: Populating EML Assembly Line templates with metadata
Step 2: Calculating the geospatial and temporal coverage 
Step 3: Making the XML file 
Step 4: Inserting a custom NES-LTER parent project node 

```{r}

# define input for EML assembly
metadata <- "eims-toi-transect/eims-toi-transect-info"
project_folder <- "eims-toi-transect/"
bottles_file <- "toi-transect"
ra_file <- "eims-transect"
edi_data <- c(bottles_file, ra_file)
file_descriptions <- c("Data product low-frequency triple oxygen isotopes and oxygen-argon ratio from surface rosette and underway bottles", "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements")
pkg_id <- "knb-lter-nes.6.1"

# Make EML Templates
xlsx_to_template(metadata.path = metadata,
                 output.path = project_folder,
                 edi.filename = "toi-transect", 
                 rights = "CCBY")
# toi bottle samples
xlsx_to_template(metadata.path = here(project_folder, bottles_file), 
                 output.path = project_folder,
                 edi.filename = bottles_file, 
                 rights = "CCBY")
# underway samples
xlsx_to_template(metadata.path = here(project_folder, ra_file), 
                 output.path = project_folder,
                 edi.filename = ra_file, 
                 rights = "CCBY")

# Data Coverage
# combine the dates for both datasets
# isolate date and geospatial columns for input
date_col <- as.Date(c(eims_edi$datetime_utc_matlab,
                      bottle_edi$datetime_utc))
lat_col <- eims_edi$latitude_API
lon_col <- eims_edi$longitude_API
# run function to determine geospatial and temporal coverage
coverage <- data_coverage(dates = date_col, lat = lat_col, lon = lon_col)

# Make EML
make_eml(path = project_folder,
         dataset.title = "Oxygen-argon dissolved gas ratios using Equilibrator Inlet Mass Spectrometry (EIMS) and triple oxygen isotopes (TOI) from NES-LTER Transect cruises, ongoing since 2018",
         data.table = c(paste0(bottles_file, ".csv"), paste0(ra_file, ".csv")),
         data.table.name = c(paste0(bottles_file, ".csv"), paste0(ra_file, ".csv")),
         data.table.description = file_descriptions,
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         #other.entity = "input_data_csv.zip",
         #other.entity.name = c(paste0("input_data_csv.zip", "input_data_matlab.zip")),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = c(coverage$startdate, coverage$enddate),
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = c(coverage$North, coverage$East, coverage$South, coverage$West),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node
project_insert(edi_pkg = pkg_id, 
               xml.path = project_folder)
```


## NCP-GOP-TRANSECT ----------

## Read in identifiers for each cruise

```{r}

cruise_list <- read_csv("cruise_list.csv", col_names = TRUE)

# edit package id to select package to assemble 
this_pkg <- cruise_list %>% filter(package_id == "knb-lter-nes.15.1")

#identify input file names
ncp_gop_csv <- paste0(this_pkg$folder, "/input_data_csv/", this_pkg$ncp_gop_input, ".csv")
ncp_hifreq_input <- paste0(this_pkg$folder, "/input_data_csv/", this_pkg$ncp_hifreq_input, ".csv")

```

## Read in Provided CSV Files

```{r}

## read in PI-provided csv data
ncp_gop_input <- read_csv(ncp_gop_csv, col_names = FALSE)
ncp_hifreq_input <- read_csv(ncp_hifreq_input, col_names = FALSE)

## ncp-gop
# provide column names
if (this_pkg$cruise_id == "EN608" | this_pkg$cruise_id == "EN617"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop")
    ncp_gop_input$depth <- NA
    ncp_gop_input$niskin <- NA
    ncp_gop_input$quality <- 0
  }
if (this_pkg$cruise_id == "EN627"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin")
    ncp_gop_input$quality <- 0
  }
if (this_pkg$cruise_id == "EN644"){
    colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin", "quality")
  }

# convert provided quality flag to iode quality flag
ncp_gop_input$iode_quality_flag <- NA_integer_
ncp_gop_input <- ncp_gop_input %>%
   mutate(iode_quality_flag = case_when(quality == 1  ~ 4,
                                        quality == 0  ~ 1,))

# check for missing data                                                                               
sum(is.na(ncp_gop_input$gop))

# replace data with NA if iode quality flag is 4
ncp_gop_input <- ncp_gop_input %>%
  mutate(gop=replace(gop, iode_quality_flag==4, NA)) %>%
  mutate(ncp=replace(ncp, iode_quality_flag==4, NA)) %>%
  mutate(ncp_per_gop=replace(ncp_per_gop, iode_quality_flag==4, NA))

# check for NAs
sum(is.na(ncp_gop_input$gop)) 

## ncp-hifreq
# provide column names
colnames(ncp_hifreq_input) <- c("datetime_utc_matlab", "O2_Ar_ratio", "temp", "sal", "latitude_matlab", "longitude_matlab", "cumulative_dist", "biosat", "ncp", "k")
ncp_hifreq <- ncp_hifreq_input %>% select(-temp, -sal, -cumulative_dist)
# add depth column to high freq EIMS data
ncp_hifreq$depth <- 5

##convert datetime format
ncp_gop_input$datetime_utc_matlab <- as.POSIXct(ncp_gop_input$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")
ncp_hifreq$datetime_utc_matlab <- as.POSIXct(ncp_hifreq$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")

```

# Bind with TOI data to identify TOI_source and supply API-provided timestamp, latitude, and longitude

```{r}



## read in toi data product table
toi_transect <- read_csv("eims-toi-transect/toi-transect.csv")

# expect toi_transect to have rows with bottles deeper than surface
# filter for rows depth less than Rachel's depthcutoff 6 m
# check for length discrepancy
# so far toi_transect only has en617
toi_transect_surface <- filter(toi_transect, cruise == this_pkg$cruise_id & depth_matlab <= 6)
nrow(toi_transect_surface)
nrow(ncp_gop_input)

## Need this hard coding if the rows with provided Niskin 99 and Depth of 999 are converted to values of 0 at outset. Don't need it if converted to NA. 
## this matching doesn't work for EN608 because 7 values are included in toi but not in discreterates input file
## 
# toi_transect_surface <- toi_transect_surface %>%
#   mutate(extras = case_when(cruise == "EN608" & datetime_utc_matlab == "2018-02-02 21:00:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-03 19:00:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-03 20:08:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-03 20:12:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-03 21:23:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-04 20:09:00" ~1,
#                             cruise == "EN608" & datetime_utc_matlab == "2018-02-04 20:41:00" ~1,
#                             TRUE ~ 0))
# 
# toi_transect_surface <- filter(toi_transect_surface, extras == 0)
# 
# nrow(toi_transect_surface)
# nrow(ncp_gop_input)

## column bind if same length
# make sure using different column names
toi_transect_surface$datetime_utc <- as.POSIXct(toi_transect_surface$datetime_utc, format="%d-%b-%Y %H:%M:%OS")
toi_transect_surface <- toi_transect_surface %>%
  rename(datetime_utc_matlab_toi = datetime_utc_matlab) %>%
  rename(depth_matlab_toi = depth_matlab)
ncp_gop_input <- ncp_gop_input %>%
  #rename(datetime_utc_matlab_ncp = datetime_utc_matlab) %>%
  rename(depth_matlab_ncp = depth) %>%
  rename(niskin_matlab_ncp = niskin)
# make sure datetime_utc_matlab and datetime_utc_matlab_toi sorted or use dplyr::arrange
ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]
# bind
ncp_gop_transect_wide <- cbind(ncp_gop_input, toi_transect_surface)

## check for correct matching in bind
# boolean check niskin and/or depth_matlab and manually inspect datetime_utc_matlab equals datetime_utc_matlab_toi 
# EN617 ncpgop_input does not have niskin or depth 
# check that matlab timestamps match for combined data sets
ncp_gop_transect_wide <- ncp_gop_transect_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_toi ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_toi ~ 1))
sum(ncp_gop_transect_wide$timecheck)  

#reorder columns and drop toi data
gopheaders <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "latitude_API", "longitude_API","toi_source", "gop", "ncp", "ncp_per_gop", "iode_quality_flag")
ncp_gop_edi <- ncp_gop_transect_wide[, gopheaders]
# EN617: keeping both sets of lat/long in output but could exclude API lat/long since matlab lat/long were checked and found to be correct in eims-toi package


```
## Add API lat/long for high-frequency data

```{r} 

#read in eims data product table
eims_transect <- read_csv("eims-toi-transect/eims-transect.csv")
#or use data frame already in environment

eims_transect_cruise <- filter(eims_transect,cruise == this_pkg$cruise_id)
nrow(eims_transect_cruise)

ncp_hifreq <- ncp_hifreq %>% filter(!is.na(datetime_utc_matlab))
nrow(ncp_hifreq)
# column bind if same length

# make sure using different column names
eims_transect_cruise <- eims_transect_cruise %>%
  rename(datetime_utc_matlab_eims = datetime_utc_matlab) %>%
  rename(latitude_matlab_eims = latitude_matlab) %>%
  rename(longitude_matlab_eims = longitude_matlab) %>%
  rename(depth_eims = depth) %>%
  rename(biosat_eims = biosat) %>%
  rename(O2_Ar_ratio_eims = O2_Ar_ratio) 
# make sure datetime_utc_matlab and datetime_utc_matlab_eims sorted or use dplyr::arrange
ncp_hifreq <- ncp_hifreq[order(ncp_hifreq$datetime_utc_matlab),]
#ncp_hifreq_wide <- left_join(ncp_hifreq, eims_transect_cruise)
ncp_hifreq_wide <- cbind(ncp_hifreq, eims_transect_cruise)

## check for correct matching in bind
# boolean check niskin and/or depth_matlab and manually inspect datetime_utc_matlab equals datetime_utc_matlab_eims
# EN617 ncpgop_input does not have niskin or depth 
# check that matlab timestamps match for combined data sets
ncp_hifreq_wide <- ncp_hifreq_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_eims ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_eims ~ 1))
sum(ncp_hifreq_wide$timecheck)  

#target columns
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab","depth", "biosat", "O2_Ar_ratio", "ncp", "k")
ncp_hifreq_edi <- ncp_hifreq_wide[, ncp_hifreq_headers]

```

## QA: Map Sampling Locations

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# Map Check

# ncp gop discrete rates with matlab coordinates
map_locs(df = ncp_gop_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = NULL)

# # ncp gop discrete rates with API coordinates
# map_locs(df = ncp_gop, xvar = "longitude_API", yvar = "latitude_API",
#          region = "transect", colorvar = NULL)

# ncp high frequency
map_locs(df = ncp_hifreq_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = NULL)


```

# Column Header Organization

```{r}

# define the desired order of columns
#ncp_gop_headers <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "toi_source", "gop", "ncp", "ncp_per_gop")
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "depth", "biosat", "O2_Ar_ratio", "ncp", "k")

# reorder columns as necessary
#ncp_gop_edi <- ncp_gop[, ncp_gop_headers]
ncp_hifreq_edi <- ncp_hifreq_edi [, ncp_hifreq_headers]

# write files for upload to EDI
write.csv(ncp_gop_edi, paste0(here(this_pkg$folder, this_pkg$gop_product), ".csv"), row.names = FALSE) #gop-transect
write.csv(ncp_hifreq_edi, paste0(here(this_pkg$folder, this_pkg$hifreq_product), ".csv"), row.names = FALSE) #ncp-transect

```


# EML Assembly: NCP-GOP-transect (Per Cruise)

This chunk outputs the final xml file for EDI through the following steps:

Step 1: Populating EML Assembly Line templates with metadata
Step 2: Calculating the geospatial and temporal coverage 
Step 3: Making the XML file 
Step 4: Inserting a custom NES-LTER parent project node 

```{r}

# define input for EML assembly
metadata <- this_pkg$metadata_file  #ncp-gop-transect-info
project_folder <- this_pkg$folder  
ncp_gop_file <- this_pkg$gop_product
ncp_hifreq_file <- this_pkg$hifreq_product
edi_data <- c(ncp_gop_file, ncp_hifreq_file)
file_descriptions <- c("Data product discrete rates of NCP and GOP from bottle TOI measurements integrated over the mixed layer", "Data product high frequency NCP derived from EIMS sampling of underway seawater")
pkg_id <- this_pkg$package_id

# Make EML Templates 
# if (file.exists(paste0(here(this_pkg$folder),"/", metadata, ".xlsx"))) {
#     print("metadata already exists")
#   } else {
xlsx_to_template(metadata.path = here(project_folder, metadata),
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = "ncp-gop-transect", 
                 rights = "CCBY")
# Discrete Rates
xlsx_to_template(metadata.path = here(project_folder, ncp_gop_file), 
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = ncp_gop_file, 
                 rights = "CCBY")
# Ncplter 
xlsx_to_template(metadata.path = here(project_folder, ncp_hifreq_file), 
                 output.path = paste0(here(this_pkg$folder),"/"),
                 edi.filename = ncp_hifreq_file, 
                 rights = "CCBY")
#}

# Data Coverage
# combine the dates and lat/lon for both datasets
# isolate date and geospatial columns for input
date_col <- as.Date(c(ncp_hifreq_edi$datetime_utc_matlab, ncp_gop_edi$datetime_utc_matlab))
lat_col <- c(ncp_hifreq_edi$latitude_matlab, ncp_gop_edi$latitude_matlab)
lon_col <- c(ncp_hifreq_edi$longitude_matlab, ncp_gop_edi$longitude_matlab)
# run function to determine geospatial and temporal coverage
coverage <- data_coverage(dates = date_col, lat = lat_col, lon = lon_col)

# Make EML
make_eml(path = here(project_folder),
         dataset.title = this_pkg$dataset_title,
         data.table = c(paste0(ncp_gop_file, ".csv"), paste0(ncp_hifreq_file, ".csv")),
         data.table.name = paste0(edi_data, ".csv"),
         data.table.description = file_descriptions,
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = c(coverage$startdate, coverage$enddate),
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = c(coverage$North, coverage$East, coverage$South, coverage$West),
         maintenance.description = "completed",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node
project_insert(edi_pkg = pkg_id, 
               xml.path = paste0(here(this_pkg$folder),"/"))

```
 
