---
title: "NES-LTER EIMS TOI and NCP-GOP Transects"
author: "Kate Morkeski, Jaxine Wolfe, Stace Beaulieu"
date: "August 19, 2023"
output: html_document
---

## R Markdown Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

# set environment timezone to UTC
Sys.setenv(TZ = "UTC")

# set path to root of project
library(here)
here("nes-lter-eims-toi-ncp-gop")

# source from Github
#remotes::install_github("WHOIGit/ediutilities")
library(ediutilities)

# define source for functions developed for assembly and EDI packaging specific to this workflow
source("prep-eims-toi-data.R")

# define R packages to require
# remotes::install_github("EDIorg/EMLassemblyline")
libs <- c("glue", "tidyverse", "readxl", "lubridate", "devtools", "EMLassemblyline", "EML", "maps", "xml2")
# load libraries
lapply(libs, require, character.only = TRUE)

```

## EIMS-TOI-TRANSECT DATA ------------

## Read in List of Cruises to Include in Package, with Cruise-Specific Info

```{r}

prior_list <- read_csv("cruise_list.csv", col_names = TRUE)
cruise_list <- read_csv("cruise_list_v3.csv", col_names = TRUE)
#cruise_list$cruise_id <- tolower(cruise_list$cruise_id)
prior_years <- c(unique(prior_list$year))
new_cruises <- c(cruise_list$cruise_id)

```

## Read in Provided TOI CSV Files and add UTC datetime, depth, and lat long for bottle samples

Add a toi_source field to the TOI data set to clarify whether a bottle was sampled from Niskin vs. underway water. 
Assign underway sampling depth.

Issues: 
  • The datetime_utc for bottle-sampled data represents the cast start time, NOT the time at which the bottle was fired
  • Differences in the given depth vs. those in the bottle summary

Solution: 
  • load in the bottle summary for the appropriate cruise
  • find the associated cast based on nearest time
  • find the time at which the bottle was fired based on API cast and PI-provided niskin
  • find the depth, latitude, and longitude for that bottle based on nearest time
  • compare the given depth to api provided
  
  Using the corrected datetimes, pull geospatial data from the underway log

```{r}

# TOI data

# for each cruise, read in toi_input, assign column names, populate cruise id, convert datetime format, ensure rows are in order, identify toi bottle source, get bottle metadata from API and match based on time, return dataframe identified with cruise id
# uses functions in prep-eims-toi-data.R

# no bucket samples are expected
# this makes no modifications to the Niskins of 99, Depth 999. They are filtered out in next chunk. 
  
for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  # function assigns column names and adds cruise identifier column
  toi <- read_toi(this$toi_input, this$cruise_id)
  # function formats datetime and puts rows in order
  toi <- time_toi(toi$datetime_utc_matlab)
  
  # function identifies toi source based on Niskin value and assigns underway sample depth to ship's intake depth (from 0 m)
  # note to check for discrepancies
  toi <- set_toi_source(toi$niskin, toi$depth_matlab, toi$toi_source)
  
  # read in api data for Niskin samples for given cruise
  summary <- read_from_api(type = "summary", cruises = cruisename)
  summary$cruise <- tolower(summary$cruise)
  
  # create columns to populate from API 
  toi$cast <- NA_integer_
  toi$depth_API <- NA_integer_
  toi$datetime_utc_API <- as.POSIXct(NA)
  toi$latitude_API <- NA_integer_
  toi$longitude_API <- NA_integer_
  
  # match API data to TOI data based on datetime
  # get cast, depth, datetime, lat, long from API
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if underway
    if (is.na(nisk)) {
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - summary$date))
    smry_cast <- summary$cast[ind]
    
    # populate cast column from summary
    toi$cast[i] <- smry_cast
    
    # store cast to find bottle time
    smry <- summary %>% filter(cast == smry_cast &
                                 niskin == nisk)
    
    # case: smry subset is empty  
    if (nrow(smry) == 0) {
      print(paste0(cruisename, " Niskin ", nisk, " not found in bottle summary for cast ", smry_cast))
      next
    }
    
    # add parameters from API to TOI data frame
    toi$datetime_utc_API[i] <- smry$date
    toi$depth_API[i] <- smry$depth
    toi$latitude_API[i] <- smry$latitude
    toi$longitude_API[i] <- smry$longitude
  }
  
  # make new datetime and depth columns that combine PI-provided column (for underway) with API-provided column (for niskin)
  toi <- toi %>%
    mutate(datetime_utc = case_when(toi_source =="toi_underway" ~ datetime_utc_matlab,
                                    toi_source == "toi_niskin" ~ datetime_utc_API)) %>%
    mutate(depth = case_when(toi_source =="toi_underway" ~ depth,
                             toi_source == "toi_niskin" ~ depth_API)) %>%
    mutate(depth = round(depth, 3)) # round to 1 or 2 decimal places? 
  
  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for underway bottle samples, match API lat long to sample based on datetime
  for (i in 1:nrow(toi)) {
    # store values
    nisk <- toi$niskin[i]
    sampletime <- toi$datetime_utc_matlab[i]
    
    # skip row if niskin
    if (!is.na(nisk)) {
      next
    }
    
    # skip row if time is missing
    if (is.na(sampletime)){
      next
    }
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    # different columns depending on vessel
    # toi$latitude_API[i] <- underway$latitude[ind]   
    # toi$longitude_API[i] <- underway$longitude[ind]
    if(str_detect(cruisename, 'EN') ){
    toi$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    toi$longitude_API[i] <- underway$gps_furuno_longitude[ind]
    }
    if(str_detect(cruisename, 'AR') ){
    toi$latitude_API[i] <- underway$dec_lat[ind]
    toi$longitude_API[i] <- underway$dec_lon[ind]
    }
  }

  toi$cruise_t0 <- toi$datetime_utc[1]
  toi$cruise_day<- toi$datetime_utc - toi$cruise_t0
  toi$cruise_day <-toi$cruise_day/86400
  toi$cruise_day <- as.double(toi$cruise_day)
  toi$cruise <- toupper(toi$cruise)
  
  #output data frame for cruise
  assign(paste0("toi_", cruisename), toi) 
  
  }  
  
```

# Combine individual cruise toi data into one dataframe

```{r}

# combine all cruises
bottle_list <- paste0("toi_", new_cruises)
bottle <- list_rbind(mget(bottle_list))
#bottle <- filter(bottle, cruise != "EN617")

# (special cases for version 2)
# # remove samples recorded with Niskin 99 (and depth 999). These were related to an experiment. 
 excl_niskin99 <- bottle %>% filter(niskin == "99")
 excl_niskin99$reason <- "niskin 99"
 bottle <- bottle %>% filter(niskin != "99" | is.na(niskin))
# 
# # exclude for now casts affected by provided incorrect cast start time
# bottle$reason <- ifelse(bottle$cruise == "EN644" & bottle$cast == 8 | 
#                         bottle$cruise == "EN644" & bottle$cast == 9 | 
#                         bottle$cruise == "EN644" & bottle$cast == 18 | 
#                         bottle$cruise == "EN644" & bottle$cast == 20 |
#                         bottle$cruise == "EN644" & bottle$cast == 26 |
#                         bottle$cruise == "AR34B" & bottle$cast == 18,
#                         yes = "incorrect cast start time", 
#                         no = NA)
#
#excl_bottlecasttime <- bottle %>% filter(!is.na(reason))
#
#bottle <- bottle %>% filter(is.na(reason))
#bottle <- bottle %>% select(-reason)

# ensure rows are in time order
bottle <- bottle[order(bottle$datetime_utc),]

```
## QA for TOI data

• compare the provided time to API-matched time
• compare the provided depth to API-matched depth
• check for Niskins not found in API
• check for samples recorded as Niskin with depth of 0
• check for underway samples with provided depth not 0
• isolate underway samples for visual comparison to event log

```{r}

# add quality flag
bottle$iode_quality_flag <- as.character("1")

# check time differences
# add time difference column
bottle$time_diff <- bottle$datetime_utc_matlab - bottle$datetime_utc_API
bottle$time_diff_min <- bottle$time_diff/60
bottle$time_diff_min <- abs(as.numeric(bottle$time_diff_min))
bottle$time_diff_min <- round(bottle$time_diff_min, 2)

# summarize time differences by cruise ## this is quick basic check of matching
bottle_time_diffs <- bottle %>%
  group_by(cruise) %>%
  summarise(avg = mean(time_diff_min, na.rm = TRUE),
            min = min(time_diff_min, na.rm = TRUE),
            max = max(time_diff_min, na.rm = TRUE))

# isolate and flag rows with time difference greater than 60 minutes
bottle <- bottle %>% mutate(iode_quality_flag = case_when(time_diff_min > 60 ~ "3",
                                                          is.na(time_diff_min) ~ "1", 
                                                          time_diff_min < 60 ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "3")
excl_time_conflicts <- bottle %>% filter(time_diff_min > 60)
excl_time_conflicts$reason <- "large time difference"

# isolate and flag instances of large depth differences
bottle$depth_diff <- bottle$depth_matlab - bottle$depth_API
bottle <- bottle %>% mutate(iode_quality_flag = case_when(abs(depth_diff) > 5 ~ "3",
                                                          is.na(depth_diff) ~ "1", 
                                                          abs(depth_diff) < 5 ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "3")
excl_depth_conflicts <- bottle %>% filter(depth_diff > 5 | depth_diff < -5)
excl_depth_conflicts$reason <- "large depth difference"

# isolate and flag any niskins not found in API. This should be the same as samples printed in loop above except if removed in rbind chunk
bottle <- bottle %>% mutate(iode_quality_flag = case_when(toi_source == "toi_niskin" & is.na(depth_API) ~ "4",
                            TRUE ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "4") 
excl_api_no_niskin <- bottle %>% filter(toi_source == "toi_niskin" & is.na(depth_API))
excl_api_no_niskin$reason <- "Niskin not found in API"

# isolate and flag samples recorded as Niskin with depth of 0
bottle <- bottle %>% mutate(iode_quality_flag = case_when(toi_source == "toi_niskin" & depth_matlab == 0 ~ "4",
                            TRUE ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "4") 
excl_niskin_0 <- bottle %>% filter(toi_source == "toi_niskin" & depth_matlab == 0)
excl_niskin_0$reason <- "Niskin with provided depth = 0"

# isolate and flag any underway samples with provided depth not 0 m 
bottle <- bottle %>% mutate(iode_quality_flag = case_when(toi_source == "toi_underway" & depth_matlab != 0 ~ "4",
                            TRUE ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "4") 
excl_underway_depth <- bottle %>% filter(toi_source == "toi_underway" & depth_matlab != 0)
excl_underway_depth$reason <- "non-zero depth provided for underway sample"

# isolate and remove any missing datetime
bottle <- bottle %>% mutate(iode_quality_flag = case_when(is.na(datetime_utc) ~ "4",
                            TRUE ~ iode_quality_flag))
sum(bottle$iode_quality_flag == "4") 
excl_missing_time <- bottle %>% filter(is.na(datetime_utc))
excl_missing_time$reason <- "missing datetime"

#special cases for version 2
# # make columns match (time difference columns)
# excl_niskin99$time_diff <- NA_integer_
# excl_niskin99$time_diff_min <- NA_integer_
# excl_niskin99$depth_diff <- NA_integer_
# excl_niskin99 <- excl_niskin99 %>% relocate(reason, .after = depth_diff)

# excl_bottlecasttime$time_diff <- NA_integer_
# excl_bottlecasttime$time_diff_min <- NA_integer_
# excl_bottlecasttime$depth_diff <- NA_integer_
# excl_bottlecasttime <- excl_bottlecasttime %>% relocate(reason, .after = depth_diff)

excl_time_conflicts$depth_diff <- NA_integer_
excl_time_conflicts <- excl_time_conflicts %>% relocate(reason, .after = depth_diff)

# add all excluded rows to one data frame and export to csv
bottle_flagged <- rbind(
                         #excl_niskin99,
                         #excl_bottlecasttime,
                         excl_time_conflicts,
                         excl_depth_conflicts, 
                         excl_api_no_niskin, 
                         excl_niskin_0, 
                         excl_underway_depth,
                         excl_missing_time)
write.csv(bottle_flagged, "toi_bottle_flagged_v3.csv")

# isolate underway samples
# -> perform visual inspection of underway TOI bottle samples against event log
toi_uw_check <- bottle %>%
  filter(toi_source == "toi_underway") %>%
  select(-niskin, -cast, -depth_API, -datetime_utc_API, -depth_diff)

# check for any missing datetime
sum(is.na(bottle$datetime_utc))

```

## QA: Map TOI Bottle Sampling Locations & Plot TOI Parameters

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# Map Check
# bottle dataset does not have coordinates from matlab. Plot bottle API lat long
map_locs(df = bottle, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")
#map_locs(df = toi_AR31A, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")
#map_locs(df = toi_AR34B, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")
#map_locs(df = toi_EN608, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "toi_source")

# Plot measured parameters in bottle TOI dataset
ggplot(bottle, aes(x= datetime_utc_matlab, y = O2_Ar_ratio))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = O2_Ar_delta))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = cap_Delta_17O))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = d17O))+ geom_point()
ggplot(bottle, aes(x= datetime_utc_matlab, y = d18O))+ geom_point()

# Plot measured parameters in bottle TOI dataset
ggplot(bottle, aes(x= cruise_day, y = O2_Ar_ratio, color = cruise))+ geom_point()
ggplot(bottle, aes(x= cruise_day, y = O2_Ar_delta, color = cruise))+ geom_point()
ggplot(bottle, aes(x= cruise_day, y = cap_Delta_17O, color = cruise))+ geom_point()
ggplot(bottle, aes(x= cruise_day, y = d17O, color = cruise))+ geom_point()
ggplot(bottle, aes(x= cruise_day, y = d18O, color = cruise))+ geom_point()

```

## Write TOI output 

```{r}

# rename some columns
bottle <- bottle %>% 
  rename(datetime_utc_input = datetime_utc_matlab) %>%
  rename(depth_input = depth_matlab)

# define headers for columns in desired order
bottle_headers <- c("cruise", "datetime_utc","datetime_utc_input", "latitude_API", "longitude_API", "toi_source", "cast", "niskin", "depth", "depth_input", "O2_Ar_delta", "O2_Ar_ratio", "cap_Delta_17O", "d17O", "d18O", "iode_quality_flag")
bottle_clean <- bottle[, bottle_headers]
# write file for inspection
#write.csv(bottle_clean, here("eims-toi-transect", 'toi-transect-new-v3.csv'), row.names = FALSE)

# if previous version should have same QC procedures as v3, this should happen after combining new cruises (line 201) instead of here:
# read in previous version
#bottle_prior <- read_csv(here("eims-toi-transect", "toi-transect.csv"))

# add quality flag
#bottle_prior$iode_quality_flag <- as.character("1")

# combine previous version and new data
#bottle_edi <- rbind(bottle_clean, bottle_prior)

bottle_edi <- bottle[, bottle_headers]

# put rows are in time order
bottle_edi <- bottle_edi[order(bottle_edi$datetime_utc),]

bottle_cruise_check <- bottle_edi %>% group_by(cruise) %>% summarize(package_toi_samples = n())
write.csv(bottle_cruise_check, here("eims-toi-transect", 'cruise_toi_count.csv'), row.names = FALSE)

# write file for upload to EDI
write.csv(bottle_edi, here("eims-toi-transect", 'toi-transect.csv'), row.names = FALSE)

```
## Read in EIMS data

```{r}

## EIMS data
# read in PI-provided csv data
# provide column names
# provide cruise id
# provide depth of underway intake
# convert datetime format
# order by time
# produce dataframe for each year

for (i in 1:nrow(cruise_list)){
      
  cruisename <- cruise_list$cruise_id[i]
  this <- cruise_list %>% filter(cruise_id == cruisename) 
  
  eims <- read_eims(this$eims_input, this$cruise_id)
  eims <- time_eims(eims$datetime_utc_matlab)
  
  # check for samples without timestamp
  #missingdate <- eims %>% filter(is.na(eims$datetime_utc_matlab))
  #eims <- eims %>% filter(!is.na(eims$datetime_utc_matlab))
  
  #assign(paste0("missingdate_", cruisename), missingdate)
 
  # initialize eims lat long columns
  eims$latitude_API <- NA_integer_
  eims$longitude_API <- NA_integer_

  # read in 1-minute position underway data from NES-LTER API 
  underway <- read_from_api(type = "underway", cruises = cruisename)
  
  # for eims file
  for (i in 1:nrow(eims)) {
    # store values
    sampletime <- eims$datetime_utc_matlab[i]  
    
    # find the index of the nearest datetime
    ind <- which.min(abs(sampletime - underway$date))
    
    # store lat long 
    
    if(str_detect(cruisename, "en") ){
    eims$latitude_API[i] <- underway$gps_furuno_latitude[ind]
    eims$longitude_API[i] <- underway$gps_furuno_longitude[ind]
    }
    if(str_detect(cruisename, "ar") ){
    eims$latitude_API[i] <- underway$dec_lat[ind]
    eims$longitude_API[i] <- underway$dec_lon[ind]
    }
    if(str_detect(cruisename, "at") ){
    eims$latitude_API[i] <- underway$dec_lat[ind]
    eims$longitude_API[i] <- underway$dec_lon[ind]
    }
    
    
  }
  #eims$cruise <- toupper(eims$cruise)
  #output data frame for cruise
  assign(paste0("eims_", cruisename), eims)
  
}

```

# Assemble EIMS data from all cruises

```{r}

eims_list <- paste0("eims_", new_cruises)
eims_all <- list_rbind(mget(eims_list))

missingdates <- filter(eims_all, is.na(datetime_utc_matlab))

# put all rows without timestamp into one dataframe
#missingdates <- rbind(missingdate_EN608, missingdate_EN617, missingdate_AR31A, missingdate_EN627, missingdate_EN644, missingdate_AR34B)
# these are are row 1114 in input file RaEn608withbiosat and row 9845 in input file RaEn627withbiosat 

# write csv file for inspection
#write.csv(missingdates, "eims_missingdates.csv", row.names = FALSE) 

# combine loop output from all cruises into one dataframe, excluding those with missing timestamp
#eims_all <- rbind(eims_EN608, eims_EN617, eims_AR31A, eims_EN627, eims_EN644, eims_AR34B)
# ensure rows are in time order
eims_all <- eims_all[order(eims_all$datetime_utc_matlab),]

# consider identifying and binding them with same method used for ncp gop

```

# QA for EIMS data

```{r}

# plot values to check for outliers

#plot matlab latitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()
# overlay API latitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = latitude_matlab))+ geom_point()+geom_point(aes(y = latitude_API), color="yellow")

#plot matlab longitude vs time
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()
# overlay API longitude 
ggplot(eims_all, aes(x= datetime_utc_matlab, y = longitude_matlab))+ geom_point()+geom_point(aes(y = longitude_API), color="yellow")

# plot eims matlab lat long
map_locs(df = eims_all, xvar = "longitude_matlab", yvar = "latitude_matlab", region = "transect", color = "cruise")
# plot eims lat long from API 
map_locs(df = eims_all, xvar = "longitude_API", yvar = "latitude_API", region = "transect", color = "cruise")

# plot values
ggplot(eims_all, aes(x= datetime_utc_matlab, y = biosat, color = cruise))+ geom_point()
ggplot(eims_all, aes(x= datetime_utc_matlab, y = O2_Ar_ratio, color = cruise))+ geom_point()

ggplot(eims_all, aes(x= salinity, y = biosat, color = cruise))+ geom_point()
ggsave("all-salinity-biosat.png")
ggplot(eims_all, aes(x= salinity, y = O2_Ar_ratio, color = cruise))+ geom_point()
ggsave("all-salinity-O2AR.png")
ggplot(eims_all, aes(x= temperature, y = biosat, color = cruise))+ geom_point()
ggsave("all-temperature-biosat.png")
ggplot(eims_all, aes(x= temperature, y = O2_Ar_ratio, color = cruise))+ geom_point()
ggsave("all-temperature-O2AR.png")

```
```{r}

sal_check <- eims_all %>% filter(salinity < 30 | salinity > 37)

print(unique(sal_check$cruise))

ggplot(eims_en608, aes(x= salinity, y = biosat, color = datetime_utc_matlab))+ geom_point()+labs(title = "EN608")
ggsave("en608-salinity-biosat.png")
ggplot(eims_en627, aes(x= salinity, y = biosat, color = datetime_utc_matlab))+ geom_point()+labs(title = "EN627")
ggsave("en627-salinity-biosat.png")
ggplot(eims_en649, aes(x= salinity, y = biosat, color = datetime_utc_matlab))+ geom_point()+labs(title = "EN649")
ggsave("en649-salinity-biosat.png")

ggplot(eims_en661, aes(x= salinity, y = biosat, color = datetime_utc_matlab))+ geom_point()+labs(title = "EN661")
ggsave("en661-salinity-biosat.png")
ggplot(eims_at46, aes(x= salinity, y = biosat, color = datetime_utc_matlab))+ geom_point()+labs(title = "AT461")
ggsave("at46-salinity-biosat.png")

```




## QA: Check for location differences

```{r}

# isolate instances of large lat/long differences
eims_all$lat_diff <- eims_all$latitude_matlab - eims_all$latitude_API
eims_all$long_diff <- eims_all$longitude_matlab - eims_all$longitude_API

# isolating differences of 0.002 decimal degrees = approximately 200 m 
pos_check <- eims_all %>%
  filter(abs(lat_diff) > 0.002 | abs(long_diff) > 0.002)

# version 2: 
    # EN617: identified two instances where values differ, and API output appears to be in error for those two data points. Use PI-provided lat/long. 
    # AR34B supplies 39 of these 53 records! Based on REST API, not R2R
# version 3: 112 observations of 215,741 are outside 200m 
  # increasing distance to 300 m reduces errant observations to 10

pos_check_300 <- eims_all %>%
  filter(abs(lat_diff) > 0.003 | abs(long_diff) > 0.003)

eims_loc_diffs <- eims_all %>%
  group_by(cruise) %>%
  summarise(avg = mean(lat_diff, na.rm = TRUE),
            min = min(lat_diff, na.rm = TRUE),
            max = max(lat_diff, na.rm = TRUE),
            avg = mean(long_diff, na.rm = TRUE),
            min = min(long_diff, na.rm = TRUE),
            max = max(long_diff, na.rm = TRUE))
# largest average difference is during EN617 and EN644

```


```{r}

# rename some columns
eims_all <- eims_all %>% 
  rename(datetime_utc = datetime_utc_matlab) %>%
  rename(latitude = latitude_matlab) %>%
  rename(longitude = longitude_matlab) 

# if previous version should have same midnight procedures as v3, this chunk should happen when reading in data instead of here.
# read in previous version
#eims_prior <- read_csv(here("eims-toi-transect", c("eims-transect-2018.csv", "eims-transect-2019.csv")))

eims_headers <- c("cruise", "datetime_utc", "latitude", "longitude", "depth", "temperature", "salinity", "biosat", "O2_Ar_ratio")
eims_all <- eims_all[, eims_headers]

# combine previous version and new data
#eims_all <- rbind(eims_all, eims_prior)
# put rows are in time order
eims_all <- eims_all[order(eims_all$datetime_utc),]

```

## Write product data files

```{r}

# separate data by year
eims_all$year <- format(eims_all$datetime_utc_matlab, "%Y")

# create data frame and output data annually
for (i in 1:nrow(cruise_list)) {
  
  cruiseyear <- cruise_list$year[i]
     
  eims_year <- eims_all %>% filter(year == cruiseyear)
  
  eims_year <- eims_year %>% select(-year)
  
  assign(paste0("eims_", cruiseyear), eims_year) 
  write.csv(eims_year, here("eims-toi-transect", paste0('eims-transect-', cruiseyear, '.csv')), row.names = FALSE)
            
}

```

## EML Assembly: EIMS-TOI-transect

Assemble EML metadata templates based on the provided Excel template

```{r}

# define input files
edi_filename <- "eims-toi-transect"
metadata <- glue('{edi_filename}/{edi_filename}-info') 
project_folder <- "eims-toi-transect"
pkg_id <- "knb-lter-nes.6.3"

# Make EML Templates 
excel_to_template(metadata_path = metadata, 
                  edi_filename = edi_filename, 
                  rights = "CCBY",
                  #other_info = TRUE, 
                  output_path = project_folder)

sheet_to_tsv('eims-toi-transect/eims-toi-transect-info.xlsx', 'CategoricalVariables',
             glue::glue('eims-toi-transect/catvars_toi-transect.txt'))

for (i in 1:nrow(cruise_list)) {
  
  cruiseyear <- cruise_list$year[i]
  
  sheet_to_tsv('eims-toi-transect/eims-toi-transect-info.xlsx', 'ColumnHeadersEims',
             glue::glue('eims-toi-transect/attributes_eims-transect-', cruiseyear, '.txt'))

}

sheet_to_tsv('eims-toi-transect/eims-toi-transect-info.xlsx', 'ColumnHeadersToi',
             glue::glue('eims-toi-transect/attributes_toi-transect.txt'))

EMLassemblyline::template_core_metadata(path= project_folder, license='CCBY')

```
Compute spatiotemporal coverage and generate EML

```{r}

# if needed, read data product csvs in order to get temporal and geographic coverage
#bottle_edi <- read.csv(here('eims-toi-transect/toi-transect.csv'))

# identify columns to generate temporal coverage and geographic coverage
temp_coverage <- temporal_coverage(bottle_edi$datetime_utc)
lat <- (bottle_edi$latitude_API)
long <- (bottle_edi$longitude_API)

# generate EML
make_eml(path=project_folder,
         data.path= here('eims-toi-transect'),
         dataset.title= 'Oxygen-argon dissolved gas ratios using Equilibrator Inlet Mass Spectrometry (EIMS) and triple oxygen isotopes (TOI) from NES-LTER Transect cruises, ongoing since 2018',
         data.table=c('toi-transect.csv',
                      'eims-transect-2018.csv',
                      'eims-transect-2019.csv', 'eims-transect-2020.csv', 'eims-transect-2021.csv', 'eims-transect-2022.csv'),
         data.table.description=c("Data product low-frequency triple oxygen isotopes and oxygen-argon ratio from rosette and underway bottles", 
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2018", 
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2019",
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2020",
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2021",
                                  "Data product high-frequency oxygen-argon dissolved gas ratio and biosaturation from underway EIMS measurements in 2022"),
         #data.table.name = c('toi-transect.csv',
          #            'eims-transect-2018.csv',
           #           'eims-transect-2019.csv'),
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.name = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = temp_coverage,
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = geographic_coordinates(lat, long),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node

# for ediutilities package: # need option for xml.path
#project_insert(edi_pkg = pkg_id, filename = 'parent_project.txt')

# for prep-eims-toi-data: 
add_parent(edi_pkg = pkg_id, parent_name = "parent_project_OOI.txt", xml.path = project_folder)

```

## NCP-GOP-TRANSECT ----------

## To produce per-year NCP GOP package, select cruise(s) from cruise list by manually editing package ID 

```{r}

# read in cruise-specific information
cruise_list <- read_csv("cruise_list_v3.csv", col_names = TRUE, show_col_types = FALSE)

# refer to package_identifiers.txt that matches to package for manual edit
# manually edit package id to select package to assemble 
this_pkg <- cruise_list %>% filter(package_id == "knb-lter-nes.13.3")

# get identifying info for this package
this_year <- this_pkg$year[1]
project_folder <- this_pkg$folder[1]
gop <- this_pkg$gop_product[1]
ncp <- this_pkg$hifreq_product[1]

```

## Read in Provided CSV Files

```{r}

## NCP-GOP

# read in PI-provided csv data and provide column names                  
for (i in 1:nrow(this_pkg)){
  
  cruise <- this_pkg$cruise_id[i]
  this_cruise <- this_pkg %>% filter(cruise_id == cruise) 
  
  # read csv
  ncp_gop_csv <- paste0(this_cruise$folder, "/input_data_csv/", this_cruise$ncp_gop_input, ".csv")
  ncp_gop_input <- read_csv(ncp_gop_csv, col_names = FALSE, show_col_types = FALSE)

  # provide column names
  # refer to cruise list csv to relate number of columns in provided discrete rates csv
    if (this_cruise$discreterates_cols == "6"){
      colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop") # 6 columns
      ncp_gop_input$depth <- NA
      ncp_gop_input$niskin <- NA
      ncp_gop_input$quality <- 0
    } else if 
    (this_cruise$discreterates_cols == "8"){
      colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin") # 8 columns
      ncp_gop_input$quality <- 0
    }
    else if (this_cruise$discreterates_cols == "9"){
      colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin", "quality") # 9 columns
    }
  else if (this_cruise$discreterates_cols == "11"){
      colnames(ncp_gop_input) <- c("datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "gop", "ncp","ncp_per_gop", "depth", "niskin", "blank", "toi_bottle", "quality") 
      #need to remove blank column and add toi_bottle to other dfs # 11 columns
    }
  
  # add cruise ID
   ncp_gop_input$cruiseid <- cruise
   ncp_gop_input <- ncp_gop_input %>% relocate(cruiseid, .before = datetime_utc_matlab)
   
   # add cruise day for plotting
   # convert datetime format
   ncp_gop_input$datetime_utc_matlab <- as.POSIXct(ncp_gop_input$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")
   ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]
   ncp_gop_input$cruise_t0 <- ncp_gop_input$datetime_utc_matlab[1]
   ncp_gop_input$cruise_day<- ncp_gop_input$datetime_utc_matlab - ncp_gop_input$cruise_t0
   ncp_gop_input$cruise_day <- ncp_gop_input$cruise_day/86400
   ncp_gop_input$cruise_day <- as.double(ncp_gop_input$cruise_day)

   # output data frame for cruise
  assign(paste0("ncp_gop_", cruise), ncp_gop_input) 
  
}

# identify names of cruise dataframes
this_pkg <- this_pkg %>% mutate(ncp_gop_df = paste0("ncp_gop_", cruise_id))
ncp_gop_names <- this_pkg$ncp_gop_df

# combine cruises for the package into one dataframe
ncp_gop_input <- map_dfr(mget(ncp_gop_names), list)

## NCP-high-frequency

# read in PI-provided csv data and provide column names and underway depth
for (i in 1:nrow(this_pkg)){
  
  cruise <- this_pkg$cruise_id[i]
  this_cruise <- this_pkg %>% filter(cruise_id == cruise) 
  
  # read csv
  ncp_hifreq_csv <- paste0(this_cruise$folder, "/input_data_csv/", this_cruise$ncp_hifreq_input, ".csv")
  ncp_hifreq_input <- read_csv(ncp_hifreq_csv, col_names = FALSE, show_col_types = FALSE)

  # provide column names
  colnames(ncp_hifreq_input) <- c("datetime_utc_matlab", "O2_Ar_ratio", "temp", "sal", "latitude_matlab", "longitude_matlab", "cumulative_dist", "biosat", "ncp", "k")
  
   # add cruise ID
  ncp_hifreq_input$cruiseid <- cruise
   ncp_hifreq_input <- ncp_hifreq_input %>% relocate(cruiseid, .before = datetime_utc_matlab)
  
  # set underway depth depending on vessel
  if(str_detect(cruise, '^EN') ){
    ncp_hifreq_input$depth <- 5
  }
  if(str_detect(cruise, '^AR') ){
    ncp_hifreq_input$depth <- 2.1336
  }
   
   # add cruise day for plotting
   # convert datetime format
   ncp_hifreq_input$datetime_utc_matlab <- as.POSIXct(ncp_hifreq_input$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")
   ncp_hifreq_input <- ncp_hifreq_input[order(ncp_hifreq_input$datetime_utc_matlab),]
   ncp_hifreq_input$cruise_t0 <- ncp_hifreq_input$datetime_utc_matlab[1]
   ncp_hifreq_input$cruise_day<- ncp_hifreq_input$datetime_utc_matlab - ncp_hifreq_input$cruise_t0
   ncp_hifreq_input$cruise_day <- ncp_hifreq_input$cruise_day/86400
   ncp_hifreq_input$cruise_day <- as.double(ncp_hifreq_input$cruise_day)

  
   #output data frame for cruise
  assign(paste0("ncp_hifreq_", cruise), ncp_hifreq_input) 
  
}

# identify names of cruise dataframes
this_pkg <- this_pkg %>% mutate(ncp_hifreq_df = paste0("ncp_hifreq_", cruise_id))
ncp_hifreq_names <- this_pkg$ncp_hifreq_df

# combine cruises for the package into one dataframe
ncp_hifreq <- map_dfr(mget(ncp_hifreq_names), list)

# remove unneeded columns
ncp_hifreq <- ncp_hifreq %>% 
  select(-temp, -sal, -cumulative_dist)

# convert datetime format
#ncp_gop_input$datetime_utc_matlab <- as.POSIXct(ncp_gop_input$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")
#ncp_hifreq$datetime_utc_matlab <- as.POSIXct(ncp_hifreq$datetime_utc_matlab, format="%d-%b-%Y %H:%M:%OS")

```

# For low-frequency data, handle missing data and provide quality flags

```{r}

sum(is.na(ncp_gop_input$gop))

# convert provided quality flag to iode quality flag
ncp_gop_input$iode_quality_flag <- NA_integer_
ncp_gop_input <- ncp_gop_input %>%
   mutate(iode_quality_flag = case_when(quality == 1  ~ 4,
                                        quality == 0  ~ 1,))

# convert any NaN to NA
ncp_gop_input <- ncp_gop_input %>% 
  mutate(latitude_matlab=replace(latitude_matlab, latitude_matlab=="NaN", NA)) %>%
  mutate(longitude_matlab=replace(longitude_matlab, longitude_matlab=="NaN", NA)) %>%
  mutate(gop=replace(gop, gop=="NaN", NA)) %>%
  mutate(ncp=replace(ncp, ncp=="NaN", NA)) %>%
  mutate(ncp_per_gop=replace(ncp_per_gop, ncp_per_gop=="NaN", NA))

# update quality flag to "missing" for the rows that were NaN
ncp_gop_input <- ncp_gop_input %>% 
 mutate(iode_quality_flag = case_when(is.na(gop) & iode_quality_flag == 1 ~ 9,
                                        TRUE  ~ iode_quality_flag))

# check for missing data                                                                               
sum(is.na(ncp_gop_input$gop))

# replace data with NA if iode quality flag is 4
ncp_gop_input <- ncp_gop_input %>%
  mutate(gop=replace(gop, iode_quality_flag==4, NA)) %>%
  mutate(ncp=replace(ncp, iode_quality_flag==4, NA)) %>%
  mutate(ncp_per_gop=replace(ncp_per_gop, iode_quality_flag==4, NA))

# check for NAs
sum(is.na(ncp_gop_input$gop)) 

```
# Flag ncp-gop samples affected by incorrect cast start time

```{r}

# ensure rows are in time order
ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]

# exclude for now (mostly cruise EN644) samples affected by incorrect cast start time
# can't do this by cast number because don't have cast number
ncp_gop_input$cast_flag <- NA_integer_
ncp_gop_input <- ncp_gop_input %>%
   mutate(cast_flag = case_when(datetime_utc_matlab == "2018-02-02 09:10:00" ~ 3, #EN608 large depth difference
                                datetime_utc_matlab == "2018-02-01 17:31:00" ~ 3, # EN608
                                datetime_utc_matlab == "2018-07-22 05:00:00" ~ 3, #EN617
                                datetime_utc_matlab == "2018-07-22 08:58:00" ~ 3, #EN617
                                datetime_utc_matlab == "2018-07-23 12:59:00"  ~ 3, #EN617
                                datetime_utc_matlab == "2018-07-24 15:33:00"  ~ 3, #EN617
                                datetime_utc_matlab == "2018-10-21 17:56:00" & niskin == 2 ~ 3, # AR31A large depth difference
                                datetime_utc_matlab == "2018-10-21 17:56:00" & niskin == 10 ~ 3, # AR31A large depth difference
                                is.na(datetime_utc_matlab) ~ 3, #AR31A missing time
                                datetime_utc_matlab == "2019-08-22 00:57:00"  ~ 3, #EN644
                                datetime_utc_matlab == "2019-08-22 03:10:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-22 04:23:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-23 15:45:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-23 16:55:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-23 23:45:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-24 23:16:00"  ~ 3,
                                datetime_utc_matlab == "2019-08-21 00:48:00" ~ 3, # EN644 underway sample with non-zero provided depth
                                datetime_utc_matlab == "2019-02-01 21:39:00" & niskin == 2 ~ 3, # EN627 large depth difference
                                datetime_utc_matlab == "2019-02-02 06:29:00" & niskin == 1 ~ 3, # EN627 large depth difference
                                datetime_utc_matlab == "2019-02-03 17:42:00" & depth == 0 ~ 3, # EN627 Niskin with provided depth zero
                                datetime_utc_matlab == "2019-04-22 04:34:00"  ~ 3, #AR34B
                                TRUE ~ 0,))

# check how many rows
sum(ncp_gop_input$cast_flag)

# isolate the identified rows
ncpcasttime <- ncp_gop_input %>% filter(ncp_gop_input$cast_flag == 3)

# remove the identified rows
#ncp_gop_input <- ncp_gop_input %>% filter(ncp_gop_input$cast_flag == 0)
#ncp_gop_input <- ncp_gop_input %>% select(-cast_flag)

```


# Bind low-frequency data with TOI data to identify TOI_source and supply API-provided timestamp, latitude, and longitude

```{r}
# read in toi data product table
toi_transect <- read_csv("eims-toi-transect/toi-transect.csv", show_col_types = FALSE)
# filter by year
toi_transect$year <- format(toi_transect$datetime_utc, "%Y")
toi_transect <- toi_transect %>% filter(toi_transect$year == this_cruise$year)

# expect toi_transect to have rows with bottles deeper than surface
# filter for rows depth less than Rachel's depthcutoff 6 m
# check for length discrepancy
toi_transect_surface <- filter(toi_transect, depth_input <= 6)
#toi_transect_surface <- filter(toi_transect, depth <= 6)
nrow(toi_transect_surface)
nrow(ncp_gop_input)
```
# Identify mismatching rows

```{r}

cruise_check_surf <- toi_transect_surface %>% group_by(cruise) %>% summarize(toi_transect_surf = n())
cruise_check_ncp <- ncp_gop_input %>% group_by(cruiseid) %>% summarize(toi_transect_surf = n())
ncp_gop_input$datetime_utc_input <- ncp_gop_input$datetime_utc_matlab
diffrows <- anti_join(ncp_gop_input, toi_transect_surface, by = "datetime_utc_input")

```


```{r}
## column bind if same length
# make sure using different column names
if (nrow(toi_transect_surface) == nrow(ncp_gop_input)){
  
  #prepare columns
  toi_transect_surface$datetime_utc <- as.POSIXct(toi_transect_surface$datetime_utc, format="%d-%b-%Y %H:%M:%OS")
  toi_transect_surface <- toi_transect_surface %>%
    rename(datetime_utc_matlab_toi = datetime_utc_matlab) %>%
    rename(depth_matlab_toi = depth_matlab) %>%
    rename(iode_quality_flag_toi = iode_quality_flag)
  
  ncp_gop_input <- ncp_gop_input %>%
    rename(depth_matlab_ncp = depth) %>%
    rename(niskin_matlab_ncp = niskin)
  
  # ensure datetime_utc_matlab and datetime_utc_matlab_toi are in order
  ncp_gop_input <- ncp_gop_input[order(ncp_gop_input$datetime_utc_matlab),]
  toi_transect_surface <- toi_transect_surface[order(toi_transect_surface$datetime_utc_matlab_toi),]
  
  # bind
  ncp_gop_transect_wide <- cbind(ncp_gop_input, toi_transect_surface)
  
} else 
{rlog::log_warn(glue::glue('ncp_gop_input rows not equal to toi_transect_surface rows'))}

## check for correct matching in bind
# since EN617 ncpgop_input does not have niskin or depth, check that matlab datetimes match for combined data sets
ncp_gop_transect_wide <- ncp_gop_transect_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_toi ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_toi ~ 1))
sum(ncp_gop_transect_wide$timecheck)  
#bad_wide <- ncp_gop_transect_wide %>% filter(timecheck == 1)

# reorder columns and drop toi data
gopheaders <- c("cruise", "datetime_utc","datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "latitude_API", "longitude_API","toi_source", "gop", "ncp", "ncp_per_gop", "iode_quality_flag")
ncp_gop_edi <- ncp_gop_transect_wide[, gopheaders]
# EN617: keeping both sets of lat/long in output but could exclude API lat/long since matlab lat/long were checked and found to be correct in eims-toi package

```

# Plot NCP-GOP parameters

```{r}


ggplot(ncp_gop_transect_wide, aes(x= cruise_day, y = gop, color = cruise))+ geom_point()
ggplot(ncp_gop_transect_wide, aes(x= cruise_day, y = ncp, color = cruise))+ geom_point()
ggplot(ncp_gop_transect_wide, aes(x= cruise_day, y = ncp_per_gop, color = cruise))+ geom_point()


#ggplot(ncp_gop_edi, aes(x= datetime_utc, y = ncp))+ geom_point()
#ggplot(ncp_gop_edi, aes(x= datetime_utc, y = ncp_per_gop))+ geom_point()

```

## Add API lat/long for high-frequency data

```{r} 

#read in eims data product table
eims_transect <- read_csv(paste0("eims-toi-transect/eims-transect-", this_year, ".csv"), show_col_types = FALSE)
#or use eims by-year data frame already in environment
# eims_transect <- eims_yyyy

nrow(eims_transect)

ncp_hifreq <- ncp_hifreq %>% filter(!is.na(datetime_utc_matlab))
nrow(ncp_hifreq)
# column bind if same length

# make sure using different column names
eims_transect <- eims_transect %>%
  rename(datetime_utc_matlab_eims = datetime_utc_matlab) %>%
  rename(latitude_matlab_eims = latitude_matlab) %>%
  rename(longitude_matlab_eims = longitude_matlab) %>%
  rename(depth_eims = depth) %>%
  rename(biosat_eims = biosat) %>%
  rename(O2_Ar_ratio_eims = O2_Ar_ratio) 
# make sure datetime_utc_matlab and datetime_utc_matlab_eims sorted or use dplyr::arrange
eims_transect <- eims_transect[order(eims_transect$datetime_utc_matlab_eims),]
ncp_hifreq <- ncp_hifreq[order(ncp_hifreq$datetime_utc_matlab),]
#ncp_hifreq_wide <- left_join(ncp_hifreq, eims_transect_cruise)
ncp_hifreq_wide <- cbind(ncp_hifreq, eims_transect)

## check for correct matching in bind
# check that matlab timestamps match for combined data sets
ncp_hifreq_wide <- ncp_hifreq_wide %>%
  mutate(timecheck = case_when(datetime_utc_matlab == datetime_utc_matlab_eims ~ 0,
                              datetime_utc_matlab != datetime_utc_matlab_eims ~ 1))
sum(ncp_hifreq_wide$timecheck)  

#target columns
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab","depth", "biosat", "O2_Ar_ratio", "ncp", "k")
ncp_hifreq_edi <- ncp_hifreq_wide[, ncp_hifreq_headers]

```
# Plot NCP-GOP parameters in high-frequency data set

```{r}

ggplot(ncp_hifreq_wide, aes(x= cruise_day, y = biosat, color = cruiseid))+ geom_point()
ggplot(ncp_hifreq_wide, aes(x= cruise_day, y = O2_Ar_ratio, color = cruiseid))+ geom_point()
ggplot(ncp_hifreq_wide, aes(x= cruise_day, y = ncp, color = cruiseid))+ geom_point()
ggplot(ncp_hifreq_wide, aes(x= cruise_day, y = k, color = cruiseid))+ geom_point()

# would be helpful to color by season

```


## QA: Map Sampling Locations

Call the map_locs function from edi-utility.R to map the sampling locations. Perform a visual check.

```{r}

# ncp gop discrete rates with matlab coordinates
map_locs(df = ncp_gop_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = "cruise")

# # ncp gop discrete rates with API coordinates
# map_locs(df = ncp_gop, xvar = "longitude_API", yvar = "latitude_API",
#          region = "transect", colorvar = NULL)

# ncp high frequency
map_locs(df = ncp_hifreq_edi, xvar = "longitude_matlab", yvar = "latitude_matlab",
         region = "transect", colorvar = "cruise")


```

# Write csv files

```{r}

# define the desired order of columns
ncp_hifreq_headers <- c("cruise", "datetime_utc_matlab", "latitude_matlab", "longitude_matlab", "depth", "ncp", "k")

# reorder columns as necessary
ncp_hifreq_edi <- ncp_hifreq_edi [, ncp_hifreq_headers]

# write files for upload to EDI
write.csv(ncp_gop_edi, paste0(here(project_folder, gop), ".csv"), row.names = FALSE) #gop-transect
write.csv(ncp_hifreq_edi, paste0(here(project_folder, ncp), ".csv"), row.names = FALSE) #ncp-transect

```

## EML Assembly: NCP-GOP-transect

Assemble EML metadata templates based on the provided Excel template

```{r}

# define input files
edi_filename <- "ncp-gop-transect"
metadata <- '/{edi_filename}-info'
#project_folder <- paste0("ncp-gop-transect-", this_year, "-pkg", this_pkg$package_no[1])
pkg_id <- this_pkg$package_id[1]

# Make EML Templates 
excel_to_template(metadata_path = glue(project_folder, metadata),
                  edi_filename = edi_filename, 
                  rights = "CCBY",
                  other_info = TRUE, 
                  output_path = project_folder)

sheet_to_tsv(paste0(project_folder, '/ncp-gop-transect-info.xlsx'), 'CategoricalVariables',
             glue::glue(project_folder, '/catvars_ncp-gop-transect.txt'))

sheet_to_tsv(paste0(project_folder, '/ncp-gop-transect-info.xlsx'), 'ColumnHeadersGop',
             glue::glue(project_folder, '/attributes_gop-transect-',this_year, '.txt'))

sheet_to_tsv(paste0(project_folder, '/ncp-gop-transect-info.xlsx'), 'ColumnHeadersNcp',
             glue::glue(project_folder, '/attributes_ncp-transect-',this_year, '.txt'))

EMLassemblyline::template_core_metadata(path= project_folder, license='CCBY')

```
Compute spatiotemporal coverage and generate EML

```{r}

# read data product csvs in order to get temporal and geographic coverage
# same dataframes as ncp_gop_edi and ncp_hifreq_edi
gop_edi <- read.csv(paste0(here(project_folder, gop), ".csv")) #gop-transect
ncp_edi <- read.csv(paste0(here(project_folder, ncp), ".csv")) #ncp-transect

# identify columns to generate temporal coverage and geographic coverage
temp_coverage <- temporal_coverage(append(gop_edi$datetime_utc, ncp_edi$datetime_utc_matlab))
lat <- append(gop_edi$latitude_API, ncp_edi$latitude_matlab)
long <- append(gop_edi$longitude_API, ncp_edi$longitude_matlab)

# generate EML
make_eml(path = project_folder,
         data.path = project_folder,
         dataset.title= this_pkg$dataset_title[1],
         data.table = c(paste0(gop, ".csv"), paste0(ncp, ".csv")),
         data.table.description=c("Data product discrete rates of NCP and GOP from bottle TOI measurements integrated over the mixed layer", "Data product high frequency NCP derived from EIMS sampling of underway seawater"),
         data.table.name = c(this_pkg$gop_product[1], this_pkg$hifreq_product[1]),
         other.entity = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.name = c("input_data_csv.zip", "input_data_matlab.zip"),
         other.entity.description = c("Package input data files in csv format","Package input data files in Matlab format"),
         temporal.coverage = temp_coverage,
         geographic.description = "NES-LTER Transect",
         geographic.coordinates = geographic_coordinates(lat, long),
         maintenance.description = "ongoing",
         user.id = "NES",
         user.domain = "LTER",
         package.id = pkg_id)

# Insert Custom Project Node

# for edi_utilities
#project_insert(edi_pkg = pkg_id, xml.path = project_folder)

# for ediutilities
#project_insert(edi_pkg = pkg_id, filename = 'parent_project.txt')

# for prep-eims-toi-data: 
add_parent(edi_pkg = pkg_id, parent_name = "parent_project_OOI.txt", xml.path = project_folder)

```

